Loaded module: cuda/11.1
WARNING: There was an error checking the latest version of pip.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.17 (you have 1.4.16). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.
  check_for_updates()
wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.
wandb: Currently logged in as: rawstone (teamdp). Use `wandb login --relogin` to force relogin
wandb: Appending key for api.wandb.ai to your netrc file: /zhome/61/c/156510/.netrc
2024-10-01 12:12:14,592 INFO Number of GPUs available: 1
[I 2024-10-01 12:12:14,594] A new study created in memory with name: no-name-b143ca24-446e-4173-9113-38fb057af42d
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121214-nhe291w0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/nhe291w0
2024-10-01 12:12:15,267 INFO ###############################################
2024-10-01 12:12:15,269 INFO Running model: ResNet101 with Image Size: 299, Batch Size: 16, LR: 9.721155015862156e-05, Weight Decay: 2.0070675220851094e-05, Gamma: 2.885495126920177, Alpha: 0.39922231461280056
2024-10-01 12:12:15,270 INFO ###############################################
2024-10-01 12:12:37,432 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:12:38,057 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/9 [00:02<?, ?it/s, Loss=0.0344]Training Epoch 1:  11%|‚ñà         | 1/9 [00:02<00:19,  2.50s/it, Loss=0.0344]Training Epoch 1:  11%|‚ñà         | 1/9 [00:02<00:19,  2.50s/it, Loss=0.0357]Training Epoch 1:  11%|‚ñà         | 1/9 [00:02<00:19,  2.50s/it, Loss=0.0356]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:02<00:04,  1.43it/s, Loss=0.0356]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:02<00:04,  1.43it/s, Loss=0.034] Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:02<00:04,  1.43it/s, Loss=0.0317]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:02<00:01,  2.74it/s, Loss=0.0317]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:02<00:01,  2.74it/s, Loss=0.0265]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:02<00:01,  2.74it/s, Loss=0.0297]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:02<00:00,  4.30it/s, Loss=0.0297]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:02<00:00,  4.30it/s, Loss=0.0288]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:03<00:00,  4.30it/s, Loss=0.0198]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:03<00:00,  5.59it/s, Loss=0.0198]                                                                            Validation:   0%|          | 0/9 [00:00<?, ?it/s]Validation:  11%|‚ñà         | 1/9 [00:00<00:03,  2.66it/s]Validation:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:00<00:00, 20.74it/s]                                                         2024-10-01 12:12:42,066 INFO New best Optuna model saved with Val Score: 0.6502
wandb: - 0.004 MB of 0.004 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb: / 0.006 MB of 0.006 MB uploadedwandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb: / 0.006 MB of 0.006 MB uploadedwandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb: / 0.006 MB of 0.006 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0.65015
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.03107
wandb:      val_loss 0.03411
wandb: 
wandb: üöÄ View run trial_0 at: https://wandb.ai/teamdp/Cell_Classification/runs/nhe291w0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 4 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121214-nhe291w0/logs
[I 2024-10-01 12:12:54,951] Trial 0 finished with value: 0.6501547987616099 and parameters: {'model_name': 'ResNet101', 'img_size': 299, 'batch_size': 16, 'lr': 9.721155015862156e-05, 'weight_decay': 2.0070675220851094e-05, 'gamma': 2.885495126920177, 'alpha': 0.39922231461280056}. Best is trial 0 with value: 0.6501547987616099.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121254-42tkhz0i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/42tkhz0i
2024-10-01 12:12:55,595 INFO ###############################################
2024-10-01 12:12:55,596 INFO Running model: MobileNetV3 with Image Size: 400, Batch Size: 4, LR: 0.002065776526138414, Weight Decay: 0.0011877464403839005, Gamma: 2.4626844390032097, Alpha: 0.5043389901899245
2024-10-01 12:12:55,597 INFO ###############################################
2024-10-01 12:12:59,911 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:12:59,934 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.0726]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:22,  1.52it/s, Loss=0.0726]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:22,  1.52it/s, Loss=0.235] Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:22,  1.52it/s, Loss=0.0541]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:22,  1.52it/s, Loss=0.0945]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:22,  1.52it/s, Loss=0.0461]Training Epoch 1:  14%|‚ñà‚ñç        | 5/35 [00:00<00:03,  8.00it/s, Loss=0.0461]Training Epoch 1:  14%|‚ñà‚ñç        | 5/35 [00:00<00:03,  8.00it/s, Loss=0.441] Training Epoch 1:  14%|‚ñà‚ñç        | 5/35 [00:00<00:03,  8.00it/s, Loss=0.00619]Training Epoch 1:  14%|‚ñà‚ñç        | 5/35 [00:00<00:03,  8.00it/s, Loss=0.0442] Training Epoch 1:  14%|‚ñà‚ñç        | 5/35 [00:00<00:03,  8.00it/s, Loss=0.166] Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:00<00:01, 13.72it/s, Loss=0.166]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:00<00:01, 13.72it/s, Loss=0.246]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:00<00:01, 13.72it/s, Loss=0.0716]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:00<00:01, 13.72it/s, Loss=0.0956]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:01<00:01, 13.72it/s, Loss=0.00903]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 18.39it/s, Loss=0.00903]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 18.39it/s, Loss=0.438]  Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 18.39it/s, Loss=0.0861]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 18.39it/s, Loss=0.196] Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 18.39it/s, Loss=0.254]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:00, 22.30it/s, Loss=0.254]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:00, 22.30it/s, Loss=0.145]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:00, 22.30it/s, Loss=0.188]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:00, 22.30it/s, Loss=0.0488]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:00, 22.30it/s, Loss=0.0683]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 25.54it/s, Loss=0.0683]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 25.54it/s, Loss=0.0504]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 25.54it/s, Loss=0.0404]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 25.54it/s, Loss=0.0453]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 25.54it/s, Loss=0.0324]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 25.54it/s, Loss=0.0344]Training Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:01<00:00, 30.19it/s, Loss=0.0344]Training Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:01<00:00, 30.19it/s, Loss=0.0505]Training Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:01<00:00, 30.19it/s, Loss=0.018] Training Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:01<00:00, 30.19it/s, Loss=0.0786]Training Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:01<00:00, 30.19it/s, Loss=0.0974]Training Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:01<00:00, 30.19it/s, Loss=0.0408]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 33.72it/s, Loss=0.0408]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 33.72it/s, Loss=0.0323]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 33.72it/s, Loss=0.0406]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 33.72it/s, Loss=0.0235]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 33.72it/s, Loss=0.132] Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:01<00:00, 29.43it/s, Loss=0.132]                                                                             Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:09,  3.50it/s]Validation:  30%|‚ñà‚ñà‚ñà       | 10/33 [00:00<00:00, 32.19it/s]Validation:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 21/33 [00:00<00:00, 56.10it/s]                                                           wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.10614
wandb:      val_loss 0.68016
wandb: 
wandb: üöÄ View run trial_1 at: https://wandb.ai/teamdp/Cell_Classification/runs/42tkhz0i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121254-42tkhz0i/logs
[I 2024-10-01 12:13:04,456] Trial 1 finished with value: 0.6501547987616099 and parameters: {'model_name': 'MobileNetV3', 'img_size': 400, 'batch_size': 4, 'lr': 0.002065776526138414, 'weight_decay': 0.0011877464403839005, 'gamma': 2.4626844390032097, 'alpha': 0.5043389901899245}. Best is trial 0 with value: 0.6501547987616099.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121304-th8f5ew5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/th8f5ew5
2024-10-01 12:13:05,138 INFO ###############################################
2024-10-01 12:13:05,140 INFO Running model: ViT16 with Image Size: 224, Batch Size: 16, LR: 0.0027017615712220857, Weight Decay: 0.00014729340289576864, Gamma: 1.154207050842241, Alpha: 0.7797610847867422
2024-10-01 12:13:05,141 INFO ###############################################
2024-10-01 12:13:09,188 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:13:09,322 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s, Loss=0.35]Training Epoch 1:  11%|‚ñà         | 1/9 [00:00<00:04,  1.97it/s, Loss=0.35]Training Epoch 1:  11%|‚ñà         | 1/9 [00:00<00:04,  1.97it/s, Loss=1.93]Training Epoch 1:  11%|‚ñà         | 1/9 [00:00<00:04,  1.97it/s, Loss=0.354]Training Epoch 1:  11%|‚ñà         | 1/9 [00:00<00:04,  1.97it/s, Loss=0.511]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:00<00:00,  7.94it/s, Loss=0.511]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:00<00:00,  7.94it/s, Loss=0.298]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:00<00:00,  7.94it/s, Loss=2.66] Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:00<00:00,  7.94it/s, Loss=1.95]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:00<00:00, 12.64it/s, Loss=1.95]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:00<00:00, 12.64it/s, Loss=1.52]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:00<00:00, 12.64it/s, Loss=0.217]                                                                           Validation:   0%|          | 0/9 [00:00<?, ?it/s]Validation:  11%|‚ñà         | 1/9 [00:00<00:03,  2.33it/s]                                                         wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 1.11882
wandb:      val_loss 0.80752
wandb: 
wandb: üöÄ View run trial_2 at: https://wandb.ai/teamdp/Cell_Classification/runs/th8f5ew5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121304-th8f5ew5/logs
[I 2024-10-01 12:13:15,615] Trial 2 finished with value: 0.6501547987616099 and parameters: {'model_name': 'ViT16', 'batch_size': 16, 'lr': 0.0027017615712220857, 'weight_decay': 0.00014729340289576864, 'gamma': 1.154207050842241, 'alpha': 0.7797610847867422}. Best is trial 0 with value: 0.6501547987616099.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121315-ux4f9z1d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/ux4f9z1d
2024-10-01 12:13:16,259 INFO ###############################################
2024-10-01 12:13:16,260 INFO Running model: DenseNet121 with Image Size: 800, Batch Size: 32, LR: 1.6020814609476102e-05, Weight Decay: 3.2219443731609057e-06, Gamma: 1.9571748208591035, Alpha: 0.7701633642853211
2024-10-01 12:13:16,261 INFO ###############################################
2024-10-01 12:13:20,276 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:13:20,318 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/5 [00:03<?, ?it/s, Loss=0.168]Training Epoch 1:  20%|‚ñà‚ñà        | 1/5 [00:03<00:12,  3.22s/it, Loss=0.168]Training Epoch 1:  20%|‚ñà‚ñà        | 1/5 [00:03<00:12,  3.22s/it, Loss=0.155]Training Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:03<00:04,  1.57s/it, Loss=0.155]Training Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:04<00:04,  1.57s/it, Loss=0.188]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:04<00:02,  1.04s/it, Loss=0.188]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:04<00:02,  1.04s/it, Loss=0.121]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:04<00:00,  1.26it/s, Loss=0.121]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:04<00:00,  1.26it/s, Loss=0.173]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:04<00:00,  1.66it/s, Loss=0.173]                                                                           Validation:   0%|          | 0/5 [00:00<?, ?it/s]Validation:  20%|‚ñà‚ñà        | 1/5 [00:01<00:05,  1.48s/it]Validation:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:01<00:02,  1.45it/s]Validation:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:01<00:00,  2.29it/s]Validation:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:01<00:00,  3.15it/s]Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  4.11it/s]                                                         wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.15939
wandb:      val_loss 0.27354
wandb: 
wandb: üöÄ View run trial_3 at: https://wandb.ai/teamdp/Cell_Classification/runs/ux4f9z1d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121315-ux4f9z1d/logs
[I 2024-10-01 12:13:29,274] Trial 3 finished with value: 0.6501547987616099 and parameters: {'model_name': 'DenseNet121', 'img_size': 800, 'batch_size': 32, 'lr': 1.6020814609476102e-05, 'weight_decay': 3.2219443731609057e-06, 'gamma': 1.9571748208591035, 'alpha': 0.7701633642853211}. Best is trial 0 with value: 0.6501547987616099.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121329-xbon2av2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/xbon2av2
2024-10-01 12:13:30,017 INFO ###############################################
2024-10-01 12:13:30,019 INFO Running model: EfficientNetB0 with Image Size: 600, Batch Size: 4, LR: 0.0001821002345265734, Weight Decay: 1.0802247580676371e-05, Gamma: 2.5702697802433683, Alpha: 0.6330703998736735
2024-10-01 12:13:30,020 INFO ###############################################
2024-10-01 12:13:34,175 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:13:34,201 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.0799]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:24,  1.42it/s, Loss=0.0799]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:24,  1.42it/s, Loss=0.0864]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:24,  1.42it/s, Loss=0.0629]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:24,  1.42it/s, Loss=0.0667]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:05,  5.79it/s, Loss=0.0667]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:05,  5.79it/s, Loss=0.0495]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:05,  5.79it/s, Loss=0.0668]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:05,  5.79it/s, Loss=0.044] Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02,  9.41it/s, Loss=0.044]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:01<00:02,  9.41it/s, Loss=0.0522]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:01<00:02,  9.41it/s, Loss=0.0585]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:01<00:02,  9.41it/s, Loss=0.0796]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:01<00:02, 12.49it/s, Loss=0.0796]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:01<00:02, 12.49it/s, Loss=0.0611]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:01<00:02, 12.49it/s, Loss=0.087] Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:01<00:02, 12.49it/s, Loss=0.026]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 15.10it/s, Loss=0.026]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 15.10it/s, Loss=0.0278]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 15.10it/s, Loss=0.0476]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 15.10it/s, Loss=0.0574]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:01, 16.54it/s, Loss=0.0574]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:01, 16.54it/s, Loss=0.0223]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:01, 16.54it/s, Loss=0.0386]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:01, 16.54it/s, Loss=0.0341]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 17.96it/s, Loss=0.0341]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 17.96it/s, Loss=0.0454]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 17.96it/s, Loss=0.0825]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 17.96it/s, Loss=0.0258]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 20.05it/s, Loss=0.0258]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 20.05it/s, Loss=0.0293]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 20.05it/s, Loss=0.0741]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 20.05it/s, Loss=0.0299]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 21.86it/s, Loss=0.0299]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 21.86it/s, Loss=0.0427]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 21.86it/s, Loss=0.144] Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 21.86it/s, Loss=0.0045]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 23.34it/s, Loss=0.0045]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 23.34it/s, Loss=0.0121]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 23.34it/s, Loss=0.0188]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 23.34it/s, Loss=0.0079]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 24.50it/s, Loss=0.0079]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:02<00:00, 24.50it/s, Loss=0.00802]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:02<00:00, 24.50it/s, Loss=0.00922]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:02<00:00, 24.50it/s, Loss=0.0129] Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:02<00:00, 25.24it/s, Loss=0.0129]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:02<00:00, 25.24it/s, Loss=0.00923]                                                                               Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:13,  2.41it/s]Validation:  24%|‚ñà‚ñà‚ñç       | 8/33 [00:00<00:01, 19.35it/s]Validation:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 16/33 [00:00<00:00, 35.27it/s]Validation:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 26/33 [00:00<00:00, 51.78it/s]                                                           2024-10-01 12:13:37,453 INFO New best Optuna model saved with Val Score: 0.9164
wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0.91641
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.04613
wandb:      val_loss 0.01821
wandb: 
wandb: üöÄ View run trial_4 at: https://wandb.ai/teamdp/Cell_Classification/runs/xbon2av2
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121329-xbon2av2/logs
[I 2024-10-01 12:13:41,276] Trial 4 finished with value: 0.9164086687306502 and parameters: {'model_name': 'EfficientNetB0', 'img_size': 600, 'batch_size': 4, 'lr': 0.0001821002345265734, 'weight_decay': 1.0802247580676371e-05, 'gamma': 2.5702697802433683, 'alpha': 0.6330703998736735}. Best is trial 4 with value: 0.9164086687306502.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121341-ul71fq35
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/ul71fq35
2024-10-01 12:13:41,971 INFO ###############################################
2024-10-01 12:13:41,972 INFO Running model: ViT32 with Image Size: 224, Batch Size: 4, LR: 5.7833097822790856e-05, Weight Decay: 4.122962767948848e-06, Gamma: 1.8348857839568624, Alpha: 0.24886271816688688
2024-10-01 12:13:41,973 INFO ###############################################
2024-10-01 12:13:46,218 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:13:46,332 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.0634]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.32it/s, Loss=0.0634]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.32it/s, Loss=0.0548]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.32it/s, Loss=0.118] Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.32it/s, Loss=0.0376]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.81it/s, Loss=0.0376]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.81it/s, Loss=0.0775]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.81it/s, Loss=0.0282]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.81it/s, Loss=0.0585]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.17it/s, Loss=0.0585]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.17it/s, Loss=0.621] Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.17it/s, Loss=0.0687]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.17it/s, Loss=0.0399]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 16.11it/s, Loss=0.0399]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 16.11it/s, Loss=0.0403]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 16.11it/s, Loss=0.0784]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 16.11it/s, Loss=0.0392]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 18.14it/s, Loss=0.0392]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 18.14it/s, Loss=0.0478]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 18.14it/s, Loss=0.074] Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 18.14it/s, Loss=0.0494]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 19.50it/s, Loss=0.0494]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 19.50it/s, Loss=0.048] Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 19.50it/s, Loss=0.0527]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 19.50it/s, Loss=0.0434]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 20.65it/s, Loss=0.0434]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 20.65it/s, Loss=0.0594]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 20.65it/s, Loss=0.0491]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 20.65it/s, Loss=0.0484]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 21.76it/s, Loss=0.0484]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 21.76it/s, Loss=0.0487]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 21.76it/s, Loss=0.0554]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 21.76it/s, Loss=0.0491]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 22.57it/s, Loss=0.0491]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 22.57it/s, Loss=0.0472]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 22.57it/s, Loss=0.0473]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 22.57it/s, Loss=0.0427]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 23.28it/s, Loss=0.0427]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 23.28it/s, Loss=0.0482]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 23.28it/s, Loss=0.0398]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 23.28it/s, Loss=0.0725]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 23.74it/s, Loss=0.0725]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 23.74it/s, Loss=0.0509]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 23.74it/s, Loss=0.0467]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 23.74it/s, Loss=0.0474]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:01<00:00, 24.13it/s, Loss=0.0474]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:01<00:00, 24.13it/s, Loss=0.0282]                                                                              Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:11,  2.74it/s]Validation:  21%|‚ñà‚ñà        | 7/33 [00:00<00:01, 18.62it/s]Validation:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 14/33 [00:00<00:00, 33.17it/s]Validation:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 21/33 [00:00<00:00, 43.10it/s]Validation:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 29/33 [00:00<00:00, 52.34it/s]                                                           wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.0695
wandb:      val_loss 0.11312
wandb: 
wandb: üöÄ View run trial_5 at: https://wandb.ai/teamdp/Cell_Classification/runs/ul71fq35
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121341-ul71fq35/logs
[I 2024-10-01 12:13:56,232] Trial 5 finished with value: 0.9164086687306502 and parameters: {'model_name': 'ViT32', 'batch_size': 4, 'lr': 5.7833097822790856e-05, 'weight_decay': 4.122962767948848e-06, 'gamma': 1.8348857839568624, 'alpha': 0.24886271816688688}. Best is trial 4 with value: 0.9164086687306502.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121356-14chv48p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/14chv48p
2024-10-01 12:13:56,889 INFO ###############################################
2024-10-01 12:13:56,890 INFO Running model: EfficientNetB4 with Image Size: 500, Batch Size: 16, LR: 0.006149604046432446, Weight Decay: 4.1567860434623254e-05, Gamma: 1.042081346912988, Alpha: 0.3277458638053631
2024-10-01 12:13:56,891 INFO ###############################################
2024-10-01 12:14:01,157 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:14:01,211 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/9 [00:01<?, ?it/s, Loss=0.109]Training Epoch 1:  11%|‚ñà         | 1/9 [00:01<00:08,  1.03s/it, Loss=0.109]Training Epoch 1:  11%|‚ñà         | 1/9 [00:01<00:08,  1.03s/it, Loss=0.0872]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 2/9 [00:01<00:03,  1.98it/s, Loss=0.0872]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 2/9 [00:01<00:03,  1.98it/s, Loss=0.185] Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:02,  2.98it/s, Loss=0.185]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:02,  2.98it/s, Loss=0.0502]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:01<00:01,  3.92it/s, Loss=0.0502]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:01<00:01,  3.92it/s, Loss=0.0755]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  4.74it/s, Loss=0.0755]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  4.74it/s, Loss=0.0375]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:01<00:00,  5.44it/s, Loss=0.0375]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:01<00:00,  5.44it/s, Loss=0.132] Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:01<00:00,  6.00it/s, Loss=0.132]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:01<00:00,  6.00it/s, Loss=0.107]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:01<00:00,  6.44it/s, Loss=0.107]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:02<00:00,  6.44it/s, Loss=0.115]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:02<00:00,  6.04it/s, Loss=0.115]                                                                           Validation:   0%|          | 0/9 [00:00<?, ?it/s]Validation:  11%|‚ñà         | 1/9 [00:00<00:05,  1.43it/s]Validation:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:00<00:00,  6.26it/s]Validation:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:00<00:00, 10.84it/s]                                                         wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0.53664
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.09936
wandb:      val_loss 0.07825
wandb: 
wandb: üöÄ View run trial_6 at: https://wandb.ai/teamdp/Cell_Classification/runs/14chv48p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121356-14chv48p/logs
[I 2024-10-01 12:14:18,283] Trial 6 finished with value: 0.9164086687306502 and parameters: {'model_name': 'EfficientNetB4', 'img_size': 500, 'batch_size': 16, 'lr': 0.006149604046432446, 'weight_decay': 4.1567860434623254e-05, 'gamma': 1.042081346912988, 'alpha': 0.3277458638053631}. Best is trial 4 with value: 0.9164086687306502.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121418-b0bay7fz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/b0bay7fz
2024-10-01 12:14:27,731 INFO ###############################################
2024-10-01 12:14:27,733 INFO Running model: ViT16 with Image Size: 224, Batch Size: 8, LR: 0.006117896899907226, Weight Decay: 0.005269728656382021, Gamma: 2.193728660549146, Alpha: 0.2285086470994676
2024-10-01 12:14:27,734 INFO ###############################################
2024-10-01 12:14:31,845 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:14:31,965 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s, Loss=0.0452]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  2.10it/s, Loss=0.0452]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  2.10it/s, Loss=0.469] Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  2.10it/s, Loss=1.27] Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  2.10it/s, Loss=0.138]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  8.04it/s, Loss=0.138]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  8.04it/s, Loss=0.595]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  8.04it/s, Loss=0.177]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  8.04it/s, Loss=0.0691]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 13.02it/s, Loss=0.0691]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 13.02it/s, Loss=0.144] Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 13.02it/s, Loss=0.0305]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 13.02it/s, Loss=0.0313]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 13.02it/s, Loss=0.117] Training Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 11/18 [00:00<00:00, 18.29it/s, Loss=0.117]Training Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 11/18 [00:00<00:00, 18.29it/s, Loss=0.0629]Training Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 11/18 [00:00<00:00, 18.29it/s, Loss=0.0342]Training Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 11/18 [00:00<00:00, 18.29it/s, Loss=0.0377]Training Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 11/18 [00:00<00:00, 18.29it/s, Loss=0.0656]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:00<00:00, 21.93it/s, Loss=0.0656]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:01<00:00, 21.93it/s, Loss=0.0811]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:01<00:00, 21.93it/s, Loss=0.0359]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:01<00:00, 21.93it/s, Loss=0.00751]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:01<00:00, 23.84it/s, Loss=0.00751]                                                                               Validation:   0%|          | 0/17 [00:00<?, ?it/s]Validation:   6%|‚ñå         | 1/17 [00:00<00:07,  2.25it/s]Validation:  41%|‚ñà‚ñà‚ñà‚ñà      | 7/17 [00:00<00:00, 15.84it/s]Validation:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 15/17 [00:00<00:00, 31.07it/s]                                                           wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.19619
wandb:      val_loss 0.22231
wandb: 
wandb: üöÄ View run trial_7 at: https://wandb.ai/teamdp/Cell_Classification/runs/b0bay7fz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121418-b0bay7fz/logs
[I 2024-10-01 12:14:46,660] Trial 7 finished with value: 0.9164086687306502 and parameters: {'model_name': 'ViT16', 'batch_size': 8, 'lr': 0.006117896899907226, 'weight_decay': 0.005269728656382021, 'gamma': 2.193728660549146, 'alpha': 0.2285086470994676}. Best is trial 4 with value: 0.9164086687306502.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121446-8qxkcwt5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/8qxkcwt5
2024-10-01 12:14:47,350 INFO ###############################################
2024-10-01 12:14:47,351 INFO Running model: ResNet18 with Image Size: 1000, Batch Size: 32, LR: 0.00023764320732413264, Weight Decay: 0.005013286499037717, Gamma: 2.9123529524252434, Alpha: 0.648973231373314
2024-10-01 12:14:47,353 INFO ###############################################
2024-10-01 12:14:51,516 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:14:51,542 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/5 [00:02<?, ?it/s, Loss=0.0807]Training Epoch 1:  20%|‚ñà‚ñà        | 1/5 [00:02<00:09,  2.35s/it, Loss=0.0807]Training Epoch 1:  20%|‚ñà‚ñà        | 1/5 [00:02<00:09,  2.35s/it, Loss=0.0263]Training Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:02<00:03,  1.17s/it, Loss=0.0263]Training Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:02<00:03,  1.17s/it, Loss=0.0294]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:02<00:01,  1.38it/s, Loss=0.0294]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:03<00:01,  1.38it/s, Loss=0.0071]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:03<00:00,  1.92it/s, Loss=0.0071]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:03<00:00,  1.92it/s, Loss=0.0106]                                                                            Validation:   0%|          | 0/5 [00:00<?, ?it/s]Validation:  20%|‚ñà‚ñà        | 1/5 [00:01<00:05,  1.46s/it]Validation:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:01<00:02,  1.28it/s]Validation:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:01<00:00,  2.03it/s]                                                         wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0.41176
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.03389
wandb:      val_loss 0.01697
wandb: 
wandb: üöÄ View run trial_8 at: https://wandb.ai/teamdp/Cell_Classification/runs/8qxkcwt5
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121446-8qxkcwt5/logs
[I 2024-10-01 12:14:59,120] Trial 8 finished with value: 0.9164086687306502 and parameters: {'model_name': 'ResNet18', 'img_size': 1000, 'batch_size': 32, 'lr': 0.00023764320732413264, 'weight_decay': 0.005013286499037717, 'gamma': 2.9123529524252434, 'alpha': 0.648973231373314}. Best is trial 4 with value: 0.9164086687306502.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121459-9x3ypg2f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/9x3ypg2f
2024-10-01 12:15:00,101 INFO ###############################################
2024-10-01 12:15:00,102 INFO Running model: ResNet18 with Image Size: 1000, Batch Size: 8, LR: 2.126330137484267e-06, Weight Decay: 0.000992579828237321, Gamma: 2.8377792553786847, Alpha: 0.28886855821154694
2024-10-01 12:15:00,103 INFO ###############################################
2024-10-01 12:15:04,016 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:15:04,045 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/18 [00:01<?, ?it/s, Loss=0.0347]Training Epoch 1:   6%|‚ñå         | 1/18 [00:01<00:18,  1.07s/it, Loss=0.0347]Training Epoch 1:   6%|‚ñå         | 1/18 [00:01<00:18,  1.07s/it, Loss=0.0429]Training Epoch 1:  11%|‚ñà         | 2/18 [00:01<00:08,  1.78it/s, Loss=0.0429]Training Epoch 1:  11%|‚ñà         | 2/18 [00:01<00:08,  1.78it/s, Loss=0.0288]Training Epoch 1:  11%|‚ñà         | 2/18 [00:01<00:08,  1.78it/s, Loss=0.024] Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:01<00:03,  4.10it/s, Loss=0.024]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:01<00:03,  4.10it/s, Loss=0.0381]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:01<00:03,  4.10it/s, Loss=0.0314]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 6/18 [00:01<00:01,  6.48it/s, Loss=0.0314]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 6/18 [00:01<00:01,  6.48it/s, Loss=0.0255]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 6/18 [00:01<00:01,  6.48it/s, Loss=0.0263]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 8/18 [00:01<00:01,  7.87it/s, Loss=0.0263]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 8/18 [00:01<00:01,  7.87it/s, Loss=0.0235]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 8/18 [00:01<00:01,  7.87it/s, Loss=0.0192]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:01<00:00,  9.97it/s, Loss=0.0192]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:01<00:00,  9.97it/s, Loss=0.025] Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:01<00:00,  9.97it/s, Loss=0.0197]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 12/18 [00:01<00:00, 11.86it/s, Loss=0.0197]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 12/18 [00:01<00:00, 11.86it/s, Loss=0.0274]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 12/18 [00:01<00:00, 11.86it/s, Loss=0.0262]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 14/18 [00:01<00:00, 13.49it/s, Loss=0.0262]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 14/18 [00:02<00:00, 13.49it/s, Loss=0.03]  Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 14/18 [00:02<00:00, 13.49it/s, Loss=0.0272]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:02<00:00, 14.80it/s, Loss=0.0272]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:02<00:00, 14.80it/s, Loss=0.0259]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:02<00:00, 14.80it/s, Loss=0.0246]                                                                              Validation:   0%|          | 0/17 [00:00<?, ?it/s]Validation:   6%|‚ñå         | 1/17 [00:00<00:09,  1.72it/s]Validation:  12%|‚ñà‚ñè        | 2/17 [00:00<00:05,  2.96it/s]Validation:  18%|‚ñà‚ñä        | 3/17 [00:00<00:03,  4.03it/s]Validation:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 9/17 [00:01<00:00, 14.86it/s]Validation:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 12/17 [00:01<00:00, 13.78it/s]                                                           wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0.16409
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.02791
wandb:      val_loss 0.03488
wandb: 
wandb: üöÄ View run trial_9 at: https://wandb.ai/teamdp/Cell_Classification/runs/9x3ypg2f
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121459-9x3ypg2f/logs
[I 2024-10-01 12:15:09,799] Trial 9 finished with value: 0.9164086687306502 and parameters: {'model_name': 'ResNet18', 'img_size': 1000, 'batch_size': 8, 'lr': 2.126330137484267e-06, 'weight_decay': 0.000992579828237321, 'gamma': 2.8377792553786847, 'alpha': 0.28886855821154694}. Best is trial 4 with value: 0.9164086687306502.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121509-ifkcckx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/ifkcckx4
2024-10-01 12:15:10,501 INFO ###############################################
2024-10-01 12:15:10,502 INFO Running model: EfficientNetB0 with Image Size: 600, Batch Size: 4, LR: 0.0005611802511095515, Weight Decay: 1.1647635670827832e-06, Gamma: 1.641258127391618, Alpha: 0.890948471576652
2024-10-01 12:15:10,503 INFO ###############################################
2024-10-01 12:15:14,758 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:15:14,787 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.199]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:15,  2.18it/s, Loss=0.199]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:15,  2.18it/s, Loss=0.187]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:15,  2.18it/s, Loss=0.202]Training Epoch 1:   9%|‚ñä         | 3/35 [00:00<00:05,  6.35it/s, Loss=0.202]Training Epoch 1:   9%|‚ñä         | 3/35 [00:00<00:05,  6.35it/s, Loss=0.132]Training Epoch 1:   9%|‚ñä         | 3/35 [00:00<00:05,  6.35it/s, Loss=0.189]Training Epoch 1:   9%|‚ñä         | 3/35 [00:00<00:05,  6.35it/s, Loss=0.0776]Training Epoch 1:  17%|‚ñà‚ñã        | 6/35 [00:00<00:02, 11.34it/s, Loss=0.0776]Training Epoch 1:  17%|‚ñà‚ñã        | 6/35 [00:00<00:02, 11.34it/s, Loss=0.0977]Training Epoch 1:  17%|‚ñà‚ñã        | 6/35 [00:00<00:02, 11.34it/s, Loss=0.125] Training Epoch 1:  17%|‚ñà‚ñã        | 6/35 [00:00<00:02, 11.34it/s, Loss=0.168]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:00<00:01, 14.53it/s, Loss=0.168]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:00<00:01, 14.53it/s, Loss=0.0598]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:00<00:01, 14.53it/s, Loss=0.145] Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:00<00:01, 14.53it/s, Loss=0.0801]Training Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:00<00:01, 16.89it/s, Loss=0.0801]Training Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:01<00:01, 16.89it/s, Loss=0.0672]Training Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:01<00:01, 16.89it/s, Loss=0.0115]Training Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:01<00:01, 16.89it/s, Loss=0.118] Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 18.69it/s, Loss=0.118]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 18.69it/s, Loss=0.0472]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 18.69it/s, Loss=0.686] Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 18.69it/s, Loss=0.0512]Training Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:01<00:00, 19.96it/s, Loss=0.0512]Training Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:01<00:00, 19.96it/s, Loss=0.518] Training Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:01<00:00, 19.96it/s, Loss=0.0203]Training Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:01<00:00, 19.96it/s, Loss=0.0206]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 21.53it/s, Loss=0.0206]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 21.53it/s, Loss=0.0349]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 21.53it/s, Loss=0.00794]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 21.53it/s, Loss=0.248]  Training Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:01<00:00, 23.02it/s, Loss=0.248]Training Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:01<00:00, 23.02it/s, Loss=0.0588]Training Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:01<00:00, 23.02it/s, Loss=0.132] Training Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:01<00:00, 23.02it/s, Loss=0.0614]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 24.20it/s, Loss=0.0614]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 24.20it/s, Loss=0.0424]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 24.20it/s, Loss=0.28]  Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 24.20it/s, Loss=0.134]Training Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:01<00:00, 25.07it/s, Loss=0.134]Training Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:01<00:00, 25.07it/s, Loss=0.117]Training Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:01<00:00, 25.07it/s, Loss=0.333]Training Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:01<00:00, 25.07it/s, Loss=0.14] Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:01<00:00, 25.82it/s, Loss=0.14]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:01<00:00, 25.82it/s, Loss=0.0844]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:01<00:00, 25.82it/s, Loss=0.0766]                                                                              Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:13,  2.42it/s]Validation:  21%|‚ñà‚ñà        | 7/33 [00:00<00:01, 16.51it/s]Validation:  39%|‚ñà‚ñà‚ñà‚ñâ      | 13/33 [00:00<00:00, 27.66it/s]Validation:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 21/33 [00:00<00:00, 40.78it/s]Validation:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 32/33 [00:00<00:00, 58.98it/s]                                                           wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0.65635
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.14202
wandb:      val_loss 0.08638
wandb: 
wandb: üöÄ View run trial_10 at: https://wandb.ai/teamdp/Cell_Classification/runs/ifkcckx4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121509-ifkcckx4/logs
[I 2024-10-01 12:15:19,796] Trial 10 finished with value: 0.9164086687306502 and parameters: {'model_name': 'EfficientNetB0', 'img_size': 600, 'batch_size': 4, 'lr': 0.0005611802511095515, 'weight_decay': 1.1647635670827832e-06, 'gamma': 1.641258127391618, 'alpha': 0.890948471576652}. Best is trial 4 with value: 0.9164086687306502.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121519-58bilezy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/58bilezy
2024-10-01 12:15:20,482 INFO ###############################################
2024-10-01 12:15:20,484 INFO Running model: ViT32 with Image Size: 224, Batch Size: 4, LR: 3.291948334630008e-05, Weight Decay: 8.305724709137798e-06, Gamma: 1.6383897888790906, Alpha: 0.12509545607630163
2024-10-01 12:15:20,485 INFO ###############################################
2024-10-01 12:15:24,530 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:15:24,645 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.0383]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.43it/s, Loss=0.0383]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.43it/s, Loss=0.0219]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.43it/s, Loss=0.017] Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.43it/s, Loss=0.0133]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  9.24it/s, Loss=0.0133]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  9.24it/s, Loss=0.0526]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  9.24it/s, Loss=0.0233]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  9.24it/s, Loss=0.0114]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:01, 14.06it/s, Loss=0.0114]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:01, 14.06it/s, Loss=0.122] Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:01, 14.06it/s, Loss=0.037]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:01, 14.06it/s, Loss=0.0342]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 17.40it/s, Loss=0.0342]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 17.40it/s, Loss=0.0368]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 17.40it/s, Loss=0.017] Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 17.40it/s, Loss=0.0434]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 20.24it/s, Loss=0.0434]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 20.24it/s, Loss=0.0148]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 20.24it/s, Loss=0.0447]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 20.24it/s, Loss=0.0241]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:00<00:00, 22.01it/s, Loss=0.0241]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 22.01it/s, Loss=0.0258]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 22.01it/s, Loss=0.0232]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 22.01it/s, Loss=0.0301]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 23.46it/s, Loss=0.0301]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 23.46it/s, Loss=0.0307]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 23.46it/s, Loss=0.0435]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 23.46it/s, Loss=0.0314]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 25.14it/s, Loss=0.0314]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 25.14it/s, Loss=0.0249]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 25.14it/s, Loss=0.0228]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 25.14it/s, Loss=0.0259]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 26.47it/s, Loss=0.0259]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 26.47it/s, Loss=0.023] Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 26.47it/s, Loss=0.0248]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 26.47it/s, Loss=0.0263]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 26.47it/s, Loss=0.027] Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:01<00:00, 27.84it/s, Loss=0.027]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:01<00:00, 27.84it/s, Loss=0.0336]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:01<00:00, 27.84it/s, Loss=0.019] Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:01<00:00, 27.84it/s, Loss=0.0203]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:01<00:00, 27.84it/s, Loss=0.0275]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:01<00:00, 28.77it/s, Loss=0.0275]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:01<00:00, 28.77it/s, Loss=0.023] Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:01<00:00, 28.77it/s, Loss=0.0229]                                                                              Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:11,  2.89it/s]Validation:  24%|‚ñà‚ñà‚ñç       | 8/33 [00:00<00:01, 22.25it/s]Validation:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 15/33 [00:00<00:00, 35.64it/s]Validation:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 24/33 [00:00<00:00, 50.17it/s]                                                           2024-10-01 12:15:27,178 INFO Trial 11 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb: / 0.006 MB of 0.006 MB uploadedwandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb: | 0.006 MB of 0.006 MB uploadedwandb: / 0.006 MB of 0.006 MB uploadedwandb: - 0.006 MB of 0.006 MB uploadedwandb: \ 0.006 MB of 0.006 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_11 at: https://wandb.ai/teamdp/Cell_Classification/runs/58bilezy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:15:38,042] Trial 11 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121538-5cop7jev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/5cop7jev
2024-10-01 12:15:38,725 INFO ###############################################
2024-10-01 12:15:38,726 INFO Running model: EfficientNetB0 with Image Size: 224, Batch Size: 4, LR: 1.564536906101586e-05, Weight Decay: 5.820216188713547e-06, Gamma: 2.4175008030144527, Alpha: 0.5367075131788426
2024-10-01 12:15:38,727 INFO ###############################################
2024-10-01 12:15:42,985 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:15:43,012 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.0805]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:16,  2.02it/s, Loss=0.0805]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:16,  2.02it/s, Loss=0.0867]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:16,  2.02it/s, Loss=0.0858]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:16,  2.02it/s, Loss=0.0826]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  7.97it/s, Loss=0.0826]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  7.97it/s, Loss=0.0669]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  7.97it/s, Loss=0.0982]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  7.97it/s, Loss=0.0504]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 12.88it/s, Loss=0.0504]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 12.88it/s, Loss=0.081] Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 12.88it/s, Loss=0.106]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 12.88it/s, Loss=0.0845]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 12.88it/s, Loss=0.0606]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:00<00:01, 17.98it/s, Loss=0.0606]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:00<00:01, 17.98it/s, Loss=0.0626]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:00<00:01, 17.98it/s, Loss=0.0758]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:00<00:01, 17.98it/s, Loss=0.074] Training Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:00<00:01, 20.67it/s, Loss=0.074]Training Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:01<00:01, 20.67it/s, Loss=0.068]Training Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:01<00:01, 20.67it/s, Loss=0.0718]Training Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:01<00:01, 20.67it/s, Loss=0.0685]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:00, 22.70it/s, Loss=0.0685]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:00, 22.70it/s, Loss=0.0645]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:00, 22.70it/s, Loss=0.079] Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:00, 22.70it/s, Loss=0.0848]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:00, 22.70it/s, Loss=0.0582]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 25.30it/s, Loss=0.0582]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 25.30it/s, Loss=0.0759]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 25.30it/s, Loss=0.0597]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 25.30it/s, Loss=0.104] Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 25.30it/s, Loss=0.0668]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 27.72it/s, Loss=0.0668]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 27.72it/s, Loss=0.0598]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 27.72it/s, Loss=0.0667]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 27.72it/s, Loss=0.0681]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 27.72it/s, Loss=0.0778]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:01<00:00, 29.54it/s, Loss=0.0778]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:01<00:00, 29.54it/s, Loss=0.0903]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:01<00:00, 29.54it/s, Loss=0.0589]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:01<00:00, 29.54it/s, Loss=0.0652]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:01<00:00, 29.54it/s, Loss=0.0768]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:01<00:00, 30.87it/s, Loss=0.0768]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:01<00:00, 30.87it/s, Loss=0.0725]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:01<00:00, 30.87it/s, Loss=0.0557]                                                                              Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:11,  2.78it/s]Validation:  24%|‚ñà‚ñà‚ñç       | 8/33 [00:00<00:01, 21.16it/s]Validation:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 15/33 [00:00<00:00, 34.80it/s]Validation:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 25/33 [00:00<00:00, 52.68it/s]                                                           wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0.35294
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.07408
wandb:      val_loss 0.06578
wandb: 
wandb: üöÄ View run trial_12 at: https://wandb.ai/teamdp/Cell_Classification/runs/5cop7jev
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121538-5cop7jev/logs
[I 2024-10-01 12:15:48,024] Trial 12 finished with value: 0.9164086687306502 and parameters: {'model_name': 'EfficientNetB0', 'img_size': 224, 'batch_size': 4, 'lr': 1.564536906101586e-05, 'weight_decay': 5.820216188713547e-06, 'gamma': 2.4175008030144527, 'alpha': 0.5367075131788426}. Best is trial 4 with value: 0.9164086687306502.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121548-xnilvtss
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/xnilvtss
2024-10-01 12:15:48,691 INFO ###############################################
2024-10-01 12:15:48,692 INFO Running model: ViT32 with Image Size: 224, Batch Size: 4, LR: 8.999694373231235e-05, Weight Decay: 1.0479445557284514e-06, Gamma: 1.8059770718675756, Alpha: 0.6346493906843106
2024-10-01 12:15:48,693 INFO ###############################################
2024-10-01 12:15:52,669 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:15:52,798 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.147]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:13,  2.50it/s, Loss=0.147]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:13,  2.50it/s, Loss=0.54] Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:13,  2.50it/s, Loss=0.305]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:13,  2.50it/s, Loss=0.0261]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  9.14it/s, Loss=0.0261]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  9.14it/s, Loss=0.503] Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  9.14it/s, Loss=0.0574]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  9.14it/s, Loss=0.474] Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.31it/s, Loss=0.474]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.31it/s, Loss=0.615]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.31it/s, Loss=0.161]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.31it/s, Loss=0.107]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 16.65it/s, Loss=0.107]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 16.65it/s, Loss=0.472]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 16.65it/s, Loss=0.251]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 16.65it/s, Loss=0.299]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 18.83it/s, Loss=0.299]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 18.83it/s, Loss=0.133]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 18.83it/s, Loss=0.066]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 18.83it/s, Loss=0.114]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 19.77it/s, Loss=0.114]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 19.77it/s, Loss=0.136]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 19.77it/s, Loss=0.583]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 19.77it/s, Loss=0.14] Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 20.85it/s, Loss=0.14]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 20.85it/s, Loss=0.227]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 20.85it/s, Loss=0.255]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 20.85it/s, Loss=0.105]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 21.98it/s, Loss=0.105]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 21.98it/s, Loss=0.12] Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 21.98it/s, Loss=0.114]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 21.98it/s, Loss=0.178]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 22.84it/s, Loss=0.178]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 22.84it/s, Loss=0.199]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 22.84it/s, Loss=0.151]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 22.84it/s, Loss=0.105]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 23.47it/s, Loss=0.105]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 23.47it/s, Loss=0.177]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 23.47it/s, Loss=0.133]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 23.47it/s, Loss=0.128]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 23.66it/s, Loss=0.128]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 23.66it/s, Loss=0.125]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 23.66it/s, Loss=0.148]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 23.66it/s, Loss=0.137]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:01<00:00, 23.90it/s, Loss=0.137]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:01<00:00, 23.90it/s, Loss=0.117]                                                                             Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:13,  2.33it/s]Validation:  27%|‚ñà‚ñà‚ñã       | 9/33 [00:00<00:01, 21.61it/s]Validation:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 18/33 [00:00<00:00, 38.51it/s]Validation:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 28/33 [00:00<00:00, 54.17it/s]                                                           2024-10-01 12:15:55,595 INFO Trial 13 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_13 at: https://wandb.ai/teamdp/Cell_Classification/runs/xnilvtss
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:15:57,647] Trial 13 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121557-afbe89rb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/afbe89rb
2024-10-01 12:15:58,325 INFO ###############################################
2024-10-01 12:15:58,326 INFO Running model: ResNet50 with Image Size: 600, Batch Size: 4, LR: 2.6746668916277936e-06, Weight Decay: 0.00013295042234859146, Gamma: 1.3721171581073466, Alpha: 0.12746811004996098
2024-10-01 12:15:58,327 INFO ###############################################
2024-10-01 12:16:02,321 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:16:02,374 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.0345]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:19,  1.70it/s, Loss=0.0345]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:19,  1.70it/s, Loss=0.0349]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:19,  1.70it/s, Loss=0.0355]Training Epoch 1:   9%|‚ñä         | 3/35 [00:00<00:06,  5.09it/s, Loss=0.0355]Training Epoch 1:   9%|‚ñä         | 3/35 [00:00<00:06,  5.09it/s, Loss=0.0379]Training Epoch 1:   9%|‚ñä         | 3/35 [00:00<00:06,  5.09it/s, Loss=0.0303]Training Epoch 1:   9%|‚ñä         | 3/35 [00:00<00:06,  5.09it/s, Loss=0.0302]Training Epoch 1:  17%|‚ñà‚ñã        | 6/35 [00:00<00:03,  9.59it/s, Loss=0.0302]Training Epoch 1:  17%|‚ñà‚ñã        | 6/35 [00:00<00:03,  9.59it/s, Loss=0.0381]Training Epoch 1:  17%|‚ñà‚ñã        | 6/35 [00:00<00:03,  9.59it/s, Loss=0.0369]Training Epoch 1:  17%|‚ñà‚ñã        | 6/35 [00:00<00:03,  9.59it/s, Loss=0.0399]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:00<00:01, 13.08it/s, Loss=0.0399]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:01<00:01, 13.08it/s, Loss=0.0289]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:01<00:01, 13.08it/s, Loss=0.0272]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:01<00:01, 13.08it/s, Loss=0.0305]Training Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:01<00:01, 15.99it/s, Loss=0.0305]Training Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:01<00:01, 15.99it/s, Loss=0.034] Training Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:01<00:01, 15.99it/s, Loss=0.0344]Training Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:01<00:01, 15.99it/s, Loss=0.0388]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 18.19it/s, Loss=0.0388]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 18.19it/s, Loss=0.0331]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 18.19it/s, Loss=0.0322]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 18.19it/s, Loss=0.0341]Training Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:01<00:00, 19.85it/s, Loss=0.0341]Training Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:01<00:00, 19.85it/s, Loss=0.0388]Training Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:01<00:00, 19.85it/s, Loss=0.0356]Training Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:01<00:00, 19.85it/s, Loss=0.033] Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 21.13it/s, Loss=0.033]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 21.13it/s, Loss=0.0337]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 21.13it/s, Loss=0.0348]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:01<00:00, 21.13it/s, Loss=0.0278]Training Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:01<00:00, 22.19it/s, Loss=0.0278]Training Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:01<00:00, 22.19it/s, Loss=0.0321]Training Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:01<00:00, 22.19it/s, Loss=0.0314]Training Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:01<00:00, 22.19it/s, Loss=0.0335]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 22.94it/s, Loss=0.0335]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 22.94it/s, Loss=0.0298]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 22.94it/s, Loss=0.0366]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 22.94it/s, Loss=0.0394]Training Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:01<00:00, 23.49it/s, Loss=0.0394]Training Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:01<00:00, 23.49it/s, Loss=0.0304]Training Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:01<00:00, 23.49it/s, Loss=0.0421]Training Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:01<00:00, 23.49it/s, Loss=0.0333]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:01<00:00, 23.86it/s, Loss=0.0333]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:02<00:00, 23.86it/s, Loss=0.0403]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:02<00:00, 23.86it/s, Loss=0.0304]                                                                              Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:14,  2.26it/s]Validation:  21%|‚ñà‚ñà        | 7/33 [00:00<00:01, 15.99it/s]Validation:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 15/33 [00:00<00:00, 31.63it/s]Validation:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 23/33 [00:00<00:00, 43.60it/s]Validation:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 31/33 [00:00<00:00, 52.73it/s]                                                           2024-10-01 12:16:05,536 INFO Trial 14 pruned at epoch 1
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_14 at: https://wandb.ai/teamdp/Cell_Classification/runs/afbe89rb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:16:11,092] Trial 14 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121611-87mldjdx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_15
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/87mldjdx
2024-10-01 12:16:12,141 INFO ###############################################
2024-10-01 12:16:12,142 INFO Running model: ViT32 with Image Size: 224, Batch Size: 4, LR: 0.0004938442393226177, Weight Decay: 2.47096209720062e-05, Gamma: 2.512019984208464, Alpha: 0.46109201149805146
2024-10-01 12:16:12,144 INFO ###############################################
2024-10-01 12:16:16,464 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:16:16,605 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.0373]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.35it/s, Loss=0.0373]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.35it/s, Loss=0.187] Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.35it/s, Loss=1.08] Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.35it/s, Loss=0.664]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.96it/s, Loss=0.664]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.96it/s, Loss=0.371]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.96it/s, Loss=0.248]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.96it/s, Loss=0.0563]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:01, 14.02it/s, Loss=0.0563]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:01, 14.02it/s, Loss=0.17]  Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:01, 14.02it/s, Loss=0.314]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:01, 14.02it/s, Loss=0.201]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 17.67it/s, Loss=0.201]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 17.67it/s, Loss=0.0712]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 17.67it/s, Loss=0.0516]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 17.67it/s, Loss=0.0538]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 20.08it/s, Loss=0.0538]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 20.08it/s, Loss=0.0801]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 20.08it/s, Loss=0.16]  Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 20.08it/s, Loss=0.124]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:00<00:00, 21.79it/s, Loss=0.124]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 21.79it/s, Loss=0.0538]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 21.79it/s, Loss=0.0775]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 21.79it/s, Loss=0.0465]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 22.28it/s, Loss=0.0465]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 22.28it/s, Loss=0.0496]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 22.28it/s, Loss=0.0561]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 22.28it/s, Loss=0.0525]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 23.61it/s, Loss=0.0525]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 23.61it/s, Loss=0.0591]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 23.61it/s, Loss=0.047] Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 23.61it/s, Loss=0.0672]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 24.52it/s, Loss=0.0672]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 24.52it/s, Loss=0.0683]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 24.52it/s, Loss=0.0468]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 24.52it/s, Loss=0.109] Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 25.19it/s, Loss=0.109]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 25.19it/s, Loss=0.0733]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 25.19it/s, Loss=0.0618]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 25.19it/s, Loss=0.0586]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 25.83it/s, Loss=0.0586]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 25.83it/s, Loss=0.0886]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 25.83it/s, Loss=0.0743]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 25.83it/s, Loss=0.0482]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:01<00:00, 26.20it/s, Loss=0.0482]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:01<00:00, 26.20it/s, Loss=0.0587]                                                                              Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:11,  2.71it/s]Validation:  21%|‚ñà‚ñà        | 7/33 [00:00<00:01, 18.14it/s]Validation:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 14/33 [00:00<00:00, 32.07it/s]Validation:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 23/33 [00:00<00:00, 47.52it/s]Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:00<00:00, 60.81it/s]                                                           2024-10-01 12:16:19,289 INFO Trial 15 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_15 at: https://wandb.ai/teamdp/Cell_Classification/runs/87mldjdx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:16:21,347] Trial 15 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121621-45qr6zqb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/45qr6zqb
2024-10-01 12:16:22,028 INFO ###############################################
2024-10-01 12:16:22,029 INFO Running model: DenseNet121 with Image Size: 900, Batch Size: 4, LR: 3.5078774782517974e-05, Weight Decay: 4.664842356116465e-06, Gamma: 2.165615734990593, Alpha: 0.6014254168183231
2024-10-01 12:16:22,030 INFO ###############################################
2024-10-01 12:16:26,432 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:16:26,471 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:01<?, ?it/s, Loss=0.109]Training Epoch 1:   3%|‚ñé         | 1/35 [00:01<00:36,  1.07s/it, Loss=0.109]Training Epoch 1:   3%|‚ñé         | 1/35 [00:01<00:36,  1.07s/it, Loss=0.123]Training Epoch 1:   6%|‚ñå         | 2/35 [00:01<00:17,  1.93it/s, Loss=0.123]Training Epoch 1:   6%|‚ñå         | 2/35 [00:01<00:17,  1.93it/s, Loss=0.121]Training Epoch 1:   9%|‚ñä         | 3/35 [00:01<00:10,  3.05it/s, Loss=0.121]Training Epoch 1:   9%|‚ñä         | 3/35 [00:01<00:10,  3.05it/s, Loss=0.121]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:01<00:07,  4.15it/s, Loss=0.121]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:01<00:07,  4.15it/s, Loss=0.105]Training Epoch 1:  14%|‚ñà‚ñç        | 5/35 [00:01<00:05,  5.25it/s, Loss=0.105]Training Epoch 1:  14%|‚ñà‚ñç        | 5/35 [00:01<00:05,  5.25it/s, Loss=0.0596]Training Epoch 1:  14%|‚ñà‚ñç        | 5/35 [00:01<00:05,  5.25it/s, Loss=0.0829]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:01<00:04,  6.96it/s, Loss=0.0829]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:01<00:04,  6.96it/s, Loss=0.101] Training Epoch 1:  23%|‚ñà‚ñà‚ñé       | 8/35 [00:01<00:03,  7.41it/s, Loss=0.101]Training Epoch 1:  23%|‚ñà‚ñà‚ñé       | 8/35 [00:01<00:03,  7.41it/s, Loss=0.0833]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:01<00:03,  7.91it/s, Loss=0.0833]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:02<00:03,  7.91it/s, Loss=0.102] Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:02<00:03,  8.28it/s, Loss=0.102]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:02<00:03,  8.28it/s, Loss=0.0745]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:02<00:02,  8.67it/s, Loss=0.0745]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:02<00:02,  8.67it/s, Loss=0.0523]Training Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:02<00:02,  9.01it/s, Loss=0.0523]Training Epoch 1:  34%|‚ñà‚ñà‚ñà‚ñç      | 12/35 [00:02<00:02,  9.01it/s, Loss=0.0396]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:02<00:02,  9.28it/s, Loss=0.0396]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:02<00:02,  9.28it/s, Loss=0.0812]Training Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:02<00:02,  9.37it/s, Loss=0.0812]Training Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 14/35 [00:02<00:02,  9.37it/s, Loss=0.0352]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:02<00:02,  9.18it/s, Loss=0.0352]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:02<00:02,  9.18it/s, Loss=0.0566]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:02<00:02,  9.12it/s, Loss=0.0566]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:02<00:02,  9.12it/s, Loss=0.0447]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:02<00:02,  8.97it/s, Loss=0.0447]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:02<00:02,  8.97it/s, Loss=0.029] Training Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:02<00:01,  9.25it/s, Loss=0.029]Training Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:02<00:01,  9.25it/s, Loss=0.0404]Training Epoch 1:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 18/35 [00:03<00:01,  9.25it/s, Loss=0.0479]Training Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 20/35 [00:03<00:01,  9.73it/s, Loss=0.0479]Training Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 20/35 [00:03<00:01,  9.73it/s, Loss=0.0388]Training Epoch 1:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 20/35 [00:03<00:01,  9.73it/s, Loss=0.101] Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:03<00:01, 10.16it/s, Loss=0.101]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:03<00:01, 10.16it/s, Loss=0.0624]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:03<00:01, 10.16it/s, Loss=0.0236]Training Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:03<00:01, 10.43it/s, Loss=0.0236]Training Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:03<00:01, 10.43it/s, Loss=0.146] Training Epoch 1:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 24/35 [00:03<00:01, 10.43it/s, Loss=0.0337]Training Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:03<00:00, 10.59it/s, Loss=0.0337]Training Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:03<00:00, 10.59it/s, Loss=0.02]  Training Epoch 1:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 26/35 [00:03<00:00, 10.59it/s, Loss=0.024]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:03<00:00, 10.70it/s, Loss=0.024]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:03<00:00, 10.70it/s, Loss=0.0238]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:03<00:00, 10.70it/s, Loss=0.033] Training Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:03<00:00, 10.77it/s, Loss=0.033]Training Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:04<00:00, 10.77it/s, Loss=0.107]Training Epoch 1:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 30/35 [00:04<00:00, 10.77it/s, Loss=0.048]Training Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:04<00:00, 10.81it/s, Loss=0.048]Training Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:04<00:00, 10.81it/s, Loss=0.0358]Training Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:04<00:00, 10.81it/s, Loss=0.0887]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:04<00:00, 10.84it/s, Loss=0.0887]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:04<00:00, 10.84it/s, Loss=0.034]                                                                              Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:20,  1.56it/s]Validation:  15%|‚ñà‚ñå        | 5/33 [00:00<00:03,  8.31it/s]Validation:  27%|‚ñà‚ñà‚ñã       | 9/33 [00:00<00:01, 13.96it/s]Validation:  39%|‚ñà‚ñà‚ñà‚ñâ      | 13/33 [00:01<00:01, 18.74it/s]Validation:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 17/33 [00:01<00:00, 22.76it/s]Validation:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 21/33 [00:01<00:00, 25.98it/s]Validation:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 25/33 [00:01<00:00, 28.49it/s]Validation:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 29/33 [00:01<00:00, 30.38it/s]Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:01<00:00, 32.30it/s]                                                           wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0.80495
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.0668
wandb:      val_loss 0.04098
wandb: 
wandb: üöÄ View run trial_16 at: https://wandb.ai/teamdp/Cell_Classification/runs/45qr6zqb
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121621-45qr6zqb/logs
[I 2024-10-01 12:16:34,943] Trial 16 finished with value: 0.9164086687306502 and parameters: {'model_name': 'DenseNet121', 'img_size': 900, 'batch_size': 4, 'lr': 3.5078774782517974e-05, 'weight_decay': 4.664842356116465e-06, 'gamma': 2.165615734990593, 'alpha': 0.6014254168183231}. Best is trial 4 with value: 0.9164086687306502.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121634-6tkuqqym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_17
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/6tkuqqym
2024-10-01 12:16:35,597 INFO ###############################################
2024-10-01 12:16:35,598 INFO Running model: EfficientNetB0 with Image Size: 700, Batch Size: 8, LR: 6.205090922684696e-06, Weight Decay: 1.267643343539104e-05, Gamma: 2.6845090543336214, Alpha: 0.38475301596247546
2024-10-01 12:16:35,599 INFO ###############################################
2024-10-01 12:16:39,654 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:16:39,682 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s, Loss=0.0368]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:14,  1.15it/s, Loss=0.0368]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:14,  1.15it/s, Loss=0.036] Training Epoch 1:   6%|‚ñå         | 1/18 [00:01<00:14,  1.15it/s, Loss=0.0401]Training Epoch 1:  17%|‚ñà‚ñã        | 3/18 [00:01<00:04,  3.49it/s, Loss=0.0401]Training Epoch 1:  17%|‚ñà‚ñã        | 3/18 [00:01<00:04,  3.49it/s, Loss=0.0459]Training Epoch 1:  17%|‚ñà‚ñã        | 3/18 [00:01<00:04,  3.49it/s, Loss=0.039] Training Epoch 1:  28%|‚ñà‚ñà‚ñä       | 5/18 [00:01<00:02,  5.74it/s, Loss=0.039]Training Epoch 1:  28%|‚ñà‚ñà‚ñä       | 5/18 [00:01<00:02,  5.74it/s, Loss=0.0492]Training Epoch 1:  28%|‚ñà‚ñà‚ñä       | 5/18 [00:01<00:02,  5.74it/s, Loss=0.0459]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:01<00:01,  7.88it/s, Loss=0.0459]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:01<00:01,  7.88it/s, Loss=0.0324]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:01<00:01,  7.88it/s, Loss=0.0351]Training Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 9/18 [00:01<00:00,  9.74it/s, Loss=0.0351]Training Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 9/18 [00:01<00:00,  9.74it/s, Loss=0.041] Training Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 9/18 [00:01<00:00,  9.74it/s, Loss=0.0345]Training Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 11/18 [00:01<00:00, 11.29it/s, Loss=0.0345]Training Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 11/18 [00:01<00:00, 11.29it/s, Loss=0.0349]Training Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 11/18 [00:01<00:00, 11.29it/s, Loss=0.039] Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:01<00:00, 12.54it/s, Loss=0.039]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:01<00:00, 12.54it/s, Loss=0.0332]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:01<00:00, 12.54it/s, Loss=0.0403]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:01<00:00, 13.50it/s, Loss=0.0403]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:01<00:00, 13.50it/s, Loss=0.0332]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:01<00:00, 13.50it/s, Loss=0.0411]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 17/18 [00:01<00:00, 14.23it/s, Loss=0.0411]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 17/18 [00:02<00:00, 14.23it/s, Loss=0.045]                                                                              Validation:   0%|          | 0/17 [00:00<?, ?it/s]Validation:   6%|‚ñå         | 1/17 [00:00<00:08,  1.94it/s]Validation:  18%|‚ñà‚ñä        | 3/17 [00:00<00:02,  5.10it/s]Validation:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 10/17 [00:00<00:00, 17.80it/s]Validation:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 16/17 [00:00<00:00, 26.53it/s]                                                           2024-10-01 12:16:42,813 INFO Trial 17 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_17 at: https://wandb.ai/teamdp/Cell_Classification/runs/6tkuqqym
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:16:44,847] Trial 17 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121644-e8f8cyji
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/e8f8cyji
2024-10-01 12:16:45,512 INFO ###############################################
2024-10-01 12:16:45,513 INFO Running model: ResNet101 with Image Size: 600, Batch Size: 32, LR: 0.0002783284512515654, Weight Decay: 4.703537993920489e-05, Gamma: 1.441961002075553, Alpha: 0.22494878598022766
2024-10-01 12:16:45,514 INFO ###############################################
2024-10-01 12:16:49,885 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:16:49,966 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/5 [00:01<?, ?it/s, Loss=0.0588]Training Epoch 1:  20%|‚ñà‚ñà        | 1/5 [00:01<00:05,  1.40s/it, Loss=0.0588]Training Epoch 1:  20%|‚ñà‚ñà        | 1/5 [00:01<00:05,  1.40s/it, Loss=0.0493]Training Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:01<00:02,  1.26it/s, Loss=0.0493]Training Epoch 1:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:02<00:02,  1.26it/s, Loss=0.0476]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:02<00:01,  1.68it/s, Loss=0.0476]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:02<00:01,  1.68it/s, Loss=0.0375]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:02<00:00,  1.98it/s, Loss=0.0375]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:02<00:00,  1.98it/s, Loss=0.0377]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:02<00:00,  2.70it/s, Loss=0.0377]                                                                            Validation:   0%|          | 0/5 [00:00<?, ?it/s]Validation:  20%|‚ñà‚ñà        | 1/5 [00:01<00:04,  1.01s/it]Validation:  40%|‚ñà‚ñà‚ñà‚ñà      | 2/5 [00:01<00:01,  2.04it/s]Validation:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:01<00:00,  3.08it/s]Validation:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 4/5 [00:01<00:00,  4.07it/s]                                                         2024-10-01 12:16:54,150 INFO Trial 18 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_18 at: https://wandb.ai/teamdp/Cell_Classification/runs/e8f8cyji
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:16:56,171] Trial 18 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121656-l6srqv5h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/l6srqv5h
2024-10-01 12:16:56,835 INFO ###############################################
2024-10-01 12:16:56,836 INFO Running model: ResNet50 with Image Size: 400, Batch Size: 4, LR: 0.0011270208677782712, Weight Decay: 2.876737179502427e-06, Gamma: 2.178909481469505, Alpha: 0.6917157789455143
2024-10-01 12:16:56,837 INFO ###############################################
2024-10-01 12:17:00,821 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:17:00,866 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.105]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:17,  1.96it/s, Loss=0.105]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:17,  1.96it/s, Loss=0.0912]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:17,  1.96it/s, Loss=0.139] Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:17,  1.96it/s, Loss=0.0804]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  7.99it/s, Loss=0.0804]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  7.99it/s, Loss=0.0677]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  7.99it/s, Loss=0.111] Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  7.99it/s, Loss=0.0606]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  7.99it/s, Loss=0.272] Training Epoch 1:  23%|‚ñà‚ñà‚ñé       | 8/35 [00:00<00:01, 14.61it/s, Loss=0.272]Training Epoch 1:  23%|‚ñà‚ñà‚ñé       | 8/35 [00:00<00:01, 14.61it/s, Loss=0.0817]Training Epoch 1:  23%|‚ñà‚ñà‚ñé       | 8/35 [00:00<00:01, 14.61it/s, Loss=0.188] Training Epoch 1:  23%|‚ñà‚ñà‚ñé       | 8/35 [00:00<00:01, 14.61it/s, Loss=0.046]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:00<00:01, 18.25it/s, Loss=0.046]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:00<00:01, 18.25it/s, Loss=0.0542]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:00<00:01, 18.25it/s, Loss=0.0273]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:00<00:01, 18.25it/s, Loss=0.155] Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:00<00:01, 18.25it/s, Loss=0.0738]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:00<00:00, 22.44it/s, Loss=0.0738]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:00<00:00, 22.44it/s, Loss=0.105] Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:00, 22.44it/s, Loss=0.0212]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:00, 22.44it/s, Loss=0.04]  Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:00, 22.44it/s, Loss=0.0869]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 24.63it/s, Loss=0.0869]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 24.63it/s, Loss=0.393] Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 24.63it/s, Loss=0.0671]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 24.63it/s, Loss=0.0764]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 24.63it/s, Loss=0.053] Training Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:01<00:00, 28.11it/s, Loss=0.053]Training Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:01<00:00, 28.11it/s, Loss=0.251]Training Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:01<00:00, 28.11it/s, Loss=0.067]Training Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:01<00:00, 28.11it/s, Loss=0.128]Training Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:01<00:00, 28.11it/s, Loss=0.0908]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 31.18it/s, Loss=0.0908]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 31.18it/s, Loss=0.125] Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 31.18it/s, Loss=0.137]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 31.18it/s, Loss=0.0885]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 31.18it/s, Loss=0.0997]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:01<00:00, 31.18it/s, Loss=0.0837]Training Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:01<00:00, 34.12it/s, Loss=0.0837]Training Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:01<00:00, 34.12it/s, Loss=0.0993]Training Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:01<00:00, 34.12it/s, Loss=0.107] Training Epoch 1:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 32/35 [00:01<00:00, 34.12it/s, Loss=0.0834]                                                                              Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:12,  2.59it/s]Validation:  33%|‚ñà‚ñà‚ñà‚ñé      | 11/33 [00:00<00:00, 28.62it/s]Validation:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 22/33 [00:00<00:00, 50.99it/s]                                                           2024-10-01 12:17:03,281 INFO Trial 19 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_19 at: https://wandb.ai/teamdp/Cell_Classification/runs/l6srqv5h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:17:05,569] Trial 19 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121705-x8hmp1ig
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/x8hmp1ig
2024-10-01 12:17:06,451 INFO ###############################################
2024-10-01 12:17:06,452 INFO Running model: EfficientNetB4 with Image Size: 224, Batch Size: 4, LR: 0.00015804755747592838, Weight Decay: 0.00027967532929679514, Gamma: 2.6115846138537657, Alpha: 0.5751492246494493
2024-10-01 12:17:06,453 INFO ###############################################
2024-10-01 12:17:10,468 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:17:10,519 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.0581]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:20,  1.70it/s, Loss=0.0581]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:20,  1.70it/s, Loss=0.0726]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:20,  1.70it/s, Loss=0.058] Training Epoch 1:   9%|‚ñä         | 3/35 [00:00<00:06,  4.80it/s, Loss=0.058]Training Epoch 1:   9%|‚ñä         | 3/35 [00:00<00:06,  4.80it/s, Loss=0.0527]Training Epoch 1:   9%|‚ñä         | 3/35 [00:00<00:06,  4.80it/s, Loss=0.0589]Training Epoch 1:  14%|‚ñà‚ñç        | 5/35 [00:00<00:04,  7.28it/s, Loss=0.0589]Training Epoch 1:  14%|‚ñà‚ñç        | 5/35 [00:00<00:04,  7.28it/s, Loss=0.0631]Training Epoch 1:  14%|‚ñà‚ñç        | 5/35 [00:01<00:04,  7.28it/s, Loss=0.0726]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:01<00:03,  9.09it/s, Loss=0.0726]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:01<00:03,  9.09it/s, Loss=0.0837]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:01<00:03,  9.09it/s, Loss=0.0655]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:01<00:02, 10.48it/s, Loss=0.0655]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:01<00:02, 10.48it/s, Loss=0.0734]Training Epoch 1:  26%|‚ñà‚ñà‚ñå       | 9/35 [00:01<00:02, 10.48it/s, Loss=0.0586]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:01<00:02, 11.22it/s, Loss=0.0586]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:01<00:02, 11.22it/s, Loss=0.0554]Training Epoch 1:  31%|‚ñà‚ñà‚ñà‚ñè      | 11/35 [00:01<00:02, 11.22it/s, Loss=0.0594]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 12.07it/s, Loss=0.0594]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 12.07it/s, Loss=0.0586]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 12.07it/s, Loss=0.0626]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 12.38it/s, Loss=0.0626]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 12.38it/s, Loss=0.0757]Training Epoch 1:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 15/35 [00:01<00:01, 12.38it/s, Loss=0.0588]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:01, 13.06it/s, Loss=0.0588]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:01, 13.06it/s, Loss=0.0535]Training Epoch 1:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 17/35 [00:01<00:01, 13.06it/s, Loss=0.0475]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:01, 13.08it/s, Loss=0.0475]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:01, 13.08it/s, Loss=0.0616]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:02<00:01, 13.08it/s, Loss=0.0447]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:02<00:01, 13.75it/s, Loss=0.0447]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:02<00:01, 13.75it/s, Loss=0.049] Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 21/35 [00:02<00:01, 13.75it/s, Loss=0.0522]Training Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:02<00:00, 14.32it/s, Loss=0.0522]Training Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:02<00:00, 14.32it/s, Loss=0.055] Training Epoch 1:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 23/35 [00:02<00:00, 14.32it/s, Loss=0.0626]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:02<00:00, 14.75it/s, Loss=0.0626]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:02<00:00, 14.75it/s, Loss=0.0653]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:02<00:00, 14.75it/s, Loss=0.0709]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:02<00:00, 15.06it/s, Loss=0.0709]Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:02<00:00, 15.06it/s, Loss=0.04]  Training Epoch 1:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 27/35 [00:02<00:00, 15.06it/s, Loss=0.0572]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:02<00:00, 15.31it/s, Loss=0.0572]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:02<00:00, 15.31it/s, Loss=0.0675]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 29/35 [00:02<00:00, 15.31it/s, Loss=0.0618]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:02<00:00, 15.48it/s, Loss=0.0618]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:02<00:00, 15.48it/s, Loss=0.0683]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:02<00:00, 15.48it/s, Loss=0.049] Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:02<00:00, 15.61it/s, Loss=0.049]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:02<00:00, 15.61it/s, Loss=0.0491]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 33/35 [00:02<00:00, 15.61it/s, Loss=0.0445]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 35/35 [00:02<00:00, 13.21it/s, Loss=0.0445]                                                                              Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:13,  2.31it/s]Validation:  15%|‚ñà‚ñå        | 5/33 [00:00<00:02, 11.36it/s]Validation:  30%|‚ñà‚ñà‚ñà       | 10/33 [00:00<00:01, 20.67it/s]Validation:  45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 15/33 [00:00<00:00, 27.57it/s]Validation:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 21/33 [00:00<00:00, 34.82it/s]Validation:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 27/33 [00:00<00:00, 41.29it/s]Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 33/33 [00:01<00:00, 46.09it/s]                                                           wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0.6192
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.05975
wandb:      val_loss 0.0594
wandb: 
wandb: üöÄ View run trial_20 at: https://wandb.ai/teamdp/Cell_Classification/runs/x8hmp1ig
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121705-x8hmp1ig/logs
[I 2024-10-01 12:17:17,458] Trial 20 finished with value: 0.9164086687306502 and parameters: {'model_name': 'EfficientNetB4', 'img_size': 224, 'batch_size': 4, 'lr': 0.00015804755747592838, 'weight_decay': 0.00027967532929679514, 'gamma': 2.6115846138537657, 'alpha': 0.5751492246494493}. Best is trial 4 with value: 0.9164086687306502.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121717-hze5zftw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/hze5zftw
2024-10-01 12:17:18,109 INFO ###############################################
2024-10-01 12:17:18,110 INFO Running model: EfficientNetB4 with Image Size: 500, Batch Size: 16, LR: 0.007023203514385822, Weight Decay: 4.4209536012058066e-05, Gamma: 1.0057586764582929, Alpha: 0.29277386125377275
2024-10-01 12:17:18,111 INFO ###############################################
2024-10-01 12:17:22,366 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:17:22,420 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s, Loss=0.103]Training Epoch 1:  11%|‚ñà         | 1/9 [00:00<00:07,  1.07it/s, Loss=0.103]Training Epoch 1:  11%|‚ñà         | 1/9 [00:01<00:07,  1.07it/s, Loss=0.102]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 2/9 [00:01<00:03,  2.11it/s, Loss=0.102]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 2/9 [00:01<00:03,  2.11it/s, Loss=0.0686]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:01,  3.15it/s, Loss=0.0686]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:01,  3.15it/s, Loss=0.169] Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:01<00:01,  4.09it/s, Loss=0.169]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:01<00:01,  4.09it/s, Loss=0.0443]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  4.90it/s, Loss=0.0443]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  4.90it/s, Loss=0.15]  Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:01<00:00,  5.58it/s, Loss=0.15]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:01<00:00,  5.58it/s, Loss=0.0209]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:01<00:00,  6.11it/s, Loss=0.0209]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:01<00:00,  6.11it/s, Loss=0.0828]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:01<00:00,  6.50it/s, Loss=0.0828]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:01<00:00,  6.50it/s, Loss=0.119]                                                                            Validation:   0%|          | 0/9 [00:00<?, ?it/s]Validation:  11%|‚ñà         | 1/9 [00:00<00:06,  1.30it/s]Validation:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:00<00:00,  5.78it/s]Validation:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:00<00:00, 10.16it/s]                                                         wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0.70433
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.09475
wandb:      val_loss 0.04372
wandb: 
wandb: üöÄ View run trial_21 at: https://wandb.ai/teamdp/Cell_Classification/runs/hze5zftw
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121717-hze5zftw/logs
[I 2024-10-01 12:17:27,758] Trial 21 finished with value: 0.9164086687306502 and parameters: {'model_name': 'EfficientNetB4', 'img_size': 500, 'batch_size': 16, 'lr': 0.007023203514385822, 'weight_decay': 4.4209536012058066e-05, 'gamma': 1.0057586764582929, 'alpha': 0.29277386125377275}. Best is trial 4 with value: 0.9164086687306502.
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121727-npdgnqj7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_22
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/npdgnqj7
2024-10-01 12:17:28,461 INFO ###############################################
2024-10-01 12:17:28,462 INFO Running model: EfficientNetB4 with Image Size: 500, Batch Size: 16, LR: 3.9470112039621165e-05, Weight Decay: 5.6890111451979135e-05, Gamma: 1.3024262003818348, Alpha: 0.3861746862420855
2024-10-01 12:17:28,463 INFO ###############################################
2024-10-01 12:17:32,644 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:17:32,693 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s, Loss=0.106]Training Epoch 1:  11%|‚ñà         | 1/9 [00:00<00:07,  1.01it/s, Loss=0.106]Training Epoch 1:  11%|‚ñà         | 1/9 [00:01<00:07,  1.01it/s, Loss=0.111]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 2/9 [00:01<00:03,  2.06it/s, Loss=0.111]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 2/9 [00:01<00:03,  2.06it/s, Loss=0.106]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:01,  3.09it/s, Loss=0.106]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:01,  3.09it/s, Loss=0.109]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:01<00:01,  4.03it/s, Loss=0.109]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:01<00:01,  4.03it/s, Loss=0.101]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  4.84it/s, Loss=0.101]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  4.84it/s, Loss=0.108]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:01<00:00,  5.52it/s, Loss=0.108]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:01<00:00,  5.52it/s, Loss=0.109]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:01<00:00,  6.05it/s, Loss=0.109]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:01<00:00,  6.05it/s, Loss=0.108]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:01<00:00,  6.46it/s, Loss=0.108]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:02<00:00,  6.46it/s, Loss=0.112]                                                                           Validation:   0%|          | 0/9 [00:00<?, ?it/s]Validation:  11%|‚ñà         | 1/9 [00:00<00:05,  1.35it/s]Validation:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:00<00:00,  5.93it/s]Validation:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:00<00:00, 10.37it/s]                                                         2024-10-01 12:17:35,911 INFO Trial 22 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_22 at: https://wandb.ai/teamdp/Cell_Classification/runs/npdgnqj7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:17:37,946] Trial 22 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121737-kljftky4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/kljftky4
2024-10-01 12:17:38,617 INFO ###############################################
2024-10-01 12:17:38,618 INFO Running model: MobileNetV3 with Image Size: 500, Batch Size: 16, LR: 0.0008807914749379903, Weight Decay: 1.403719976334439e-05, Gamma: 1.8901504518656715, Alpha: 0.2889875153751286
2024-10-01 12:17:38,619 INFO ###############################################
2024-10-01 12:17:42,584 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:17:42,608 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s, Loss=0.055]Training Epoch 1:  11%|‚ñà         | 1/9 [00:00<00:07,  1.03it/s, Loss=0.055]Training Epoch 1:  11%|‚ñà         | 1/9 [00:01<00:07,  1.03it/s, Loss=0.0538]Training Epoch 1:  11%|‚ñà         | 1/9 [00:01<00:07,  1.03it/s, Loss=0.0378]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:01,  3.31it/s, Loss=0.0378]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:01,  3.31it/s, Loss=0.033] Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:01,  3.31it/s, Loss=0.0216]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  5.70it/s, Loss=0.0216]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  5.70it/s, Loss=0.0456]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  5.70it/s, Loss=0.0198]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  5.70it/s, Loss=0.161] Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:01<00:00,  9.24it/s, Loss=0.161]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:01<00:00,  9.24it/s, Loss=0.00789]                                                                             Validation:   0%|          | 0/9 [00:00<?, ?it/s]Validation:  11%|‚ñà         | 1/9 [00:00<00:05,  1.47it/s]Validation:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:00<00:00,  7.99it/s]                                                         wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:  custom_score ‚ñÅ
wandb:         epoch ‚ñÅ
wandb: learning_rate ‚ñÅ
wandb:    train_loss ‚ñÅ
wandb:      val_loss ‚ñÅ
wandb: 
wandb: Run summary:
wandb:  custom_score 0.54696
wandb:         epoch 1
wandb: learning_rate 0
wandb:    train_loss 0.04983
wandb:      val_loss 0.02087
wandb: 
wandb: üöÄ View run trial_23 at: https://wandb.ai/teamdp/Cell_Classification/runs/kljftky4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241001_121737-kljftky4/logs
[I 2024-10-01 12:17:54,089] Trial 23 finished with value: 0.9164086687306502 and parameters: {'model_name': 'MobileNetV3', 'img_size': 500, 'batch_size': 16, 'lr': 0.0008807914749379903, 'weight_decay': 1.403719976334439e-05, 'gamma': 1.8901504518656715, 'alpha': 0.2889875153751286}. Best is trial 4 with value: 0.9164086687306502.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121754-posx6ajc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/posx6ajc
2024-10-01 12:17:58,551 INFO ###############################################
2024-10-01 12:17:58,552 INFO Running model: EfficientNetB4 with Image Size: 700, Batch Size: 16, LR: 6.740944658943757e-06, Weight Decay: 2.2848695494151646e-06, Gamma: 1.6934353234051533, Alpha: 0.4410222470389981
2024-10-01 12:17:58,554 INFO ###############################################
2024-10-01 12:18:02,464 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:18:02,516 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/9 [00:01<?, ?it/s, Loss=0.0917]Training Epoch 1:  11%|‚ñà         | 1/9 [00:01<00:09,  1.14s/it, Loss=0.0917]Training Epoch 1:  11%|‚ñà         | 1/9 [00:01<00:09,  1.14s/it, Loss=0.0991]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 2/9 [00:01<00:04,  1.63it/s, Loss=0.0991]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 2/9 [00:01<00:04,  1.63it/s, Loss=0.101] Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:02,  2.24it/s, Loss=0.101]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:02,  2.24it/s, Loss=0.0987]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:01<00:01,  2.73it/s, Loss=0.0987]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:02<00:01,  2.73it/s, Loss=0.0949]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:02<00:01,  3.09it/s, Loss=0.0949]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:02<00:01,  3.09it/s, Loss=0.0916]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:02<00:00,  3.37it/s, Loss=0.0916]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:02<00:00,  3.37it/s, Loss=0.1]   Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:02<00:00,  3.56it/s, Loss=0.1]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:02<00:00,  3.56it/s, Loss=0.094]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:02<00:00,  3.71it/s, Loss=0.094]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:03<00:00,  3.71it/s, Loss=0.104]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:03<00:00,  4.12it/s, Loss=0.104]                                                                           Validation:   0%|          | 0/9 [00:00<?, ?it/s]Validation:  11%|‚ñà         | 1/9 [00:00<00:07,  1.05it/s]Validation:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:01,  3.36it/s]Validation:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  5.59it/s]Validation:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:01<00:00,  7.64it/s]Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:01<00:00,  9.71it/s]                                                         2024-10-01 12:18:07,271 INFO Trial 24 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_24 at: https://wandb.ai/teamdp/Cell_Classification/runs/posx6ajc
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:18:24,356] Trial 24 pruned. 
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121824-x2ytx16i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/x2ytx16i
2024-10-01 12:18:30,251 INFO ###############################################
2024-10-01 12:18:30,253 INFO Running model: ViT32 with Image Size: 224, Batch Size: 16, LR: 0.002365855422615123, Weight Decay: 2.506877772344753e-05, Gamma: 2.309839382200069, Alpha: 0.19340890930271834
2024-10-01 12:18:30,254 INFO ###############################################
2024-10-01 12:18:34,326 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:18:34,431 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s, Loss=0.0327]Training Epoch 1:  11%|‚ñà         | 1/9 [00:00<00:04,  1.65it/s, Loss=0.0327]Training Epoch 1:  11%|‚ñà         | 1/9 [00:00<00:04,  1.65it/s, Loss=0.337] Training Epoch 1:  11%|‚ñà         | 1/9 [00:00<00:04,  1.65it/s, Loss=0.782]Training Epoch 1:  11%|‚ñà         | 1/9 [00:00<00:04,  1.65it/s, Loss=0.35] Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:00<00:00,  6.88it/s, Loss=0.35]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:00<00:00,  6.88it/s, Loss=0.0496]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:00<00:00,  6.88it/s, Loss=0.0346]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:00<00:00,  6.88it/s, Loss=0.0265]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:00<00:00, 11.56it/s, Loss=0.0265]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:00<00:00, 11.56it/s, Loss=0.04]  Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:00<00:00, 11.56it/s, Loss=0.0268]                                                                            Validation:   0%|          | 0/9 [00:00<?, ?it/s]Validation:  11%|‚ñà         | 1/9 [00:00<00:04,  1.83it/s]Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 17.63it/s]                                                         2024-10-01 12:18:36,198 INFO Trial 25 pruned at epoch 1
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_25 at: https://wandb.ai/teamdp/Cell_Classification/runs/x2ytx16i
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:18:45,347] Trial 25 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121845-9h8e1uvt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_26
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/9h8e1uvt
2024-10-01 12:18:46,476 INFO ###############################################
2024-10-01 12:18:46,477 INFO Running model: EfficientNetB0 with Image Size: 299, Batch Size: 32, LR: 5.7164025966437324e-05, Weight Decay: 8.614437868602304e-06, Gamma: 1.4704275880799038, Alpha: 0.33158059780070576
2024-10-01 12:18:46,479 INFO ###############################################
2024-10-01 12:18:50,374 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:18:50,398 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, Loss=0.0803]Training Epoch 1:  20%|‚ñà‚ñà        | 1/5 [00:00<00:03,  1.13it/s, Loss=0.0803]Training Epoch 1:  20%|‚ñà‚ñà        | 1/5 [00:00<00:03,  1.13it/s, Loss=0.0807]Training Epoch 1:  20%|‚ñà‚ñà        | 1/5 [00:01<00:03,  1.13it/s, Loss=0.0827]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:01<00:00,  3.56it/s, Loss=0.0827]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:01<00:00,  3.56it/s, Loss=0.0668]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:01<00:00,  3.56it/s, Loss=0.0803]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:01<00:00,  5.46it/s, Loss=0.0803]                                                                            Validation:   0%|          | 0/5 [00:00<?, ?it/s]Validation:  20%|‚ñà‚ñà        | 1/5 [00:00<00:02,  1.43it/s]                                                         2024-10-01 12:18:52,575 INFO Trial 26 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_26 at: https://wandb.ai/teamdp/Cell_Classification/runs/9h8e1uvt
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:18:54,686] Trial 26 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121854-8i2ad9at
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_27
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/8i2ad9at
2024-10-01 12:18:55,457 INFO ###############################################
2024-10-01 12:18:55,458 INFO Running model: EfficientNetB4 with Image Size: 900, Batch Size: 8, LR: 1.3539057098472172e-05, Weight Decay: 0.00038239108117562464, Gamma: 2.0491937572174894, Alpha: 0.19982777117434758
2024-10-01 12:18:55,460 INFO ###############################################
2024-10-01 12:18:59,646 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:18:59,699 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/18 [00:01<?, ?it/s, Loss=0.0345]Training Epoch 1:   6%|‚ñå         | 1/18 [00:01<00:19,  1.15s/it, Loss=0.0345]Training Epoch 1:   6%|‚ñå         | 1/18 [00:01<00:19,  1.15s/it, Loss=0.0354]Training Epoch 1:  11%|‚ñà         | 2/18 [00:01<00:10,  1.52it/s, Loss=0.0354]Training Epoch 1:  11%|‚ñà         | 2/18 [00:01<00:10,  1.52it/s, Loss=0.0362]Training Epoch 1:  17%|‚ñà‚ñã        | 3/18 [00:01<00:07,  2.04it/s, Loss=0.0362]Training Epoch 1:  17%|‚ñà‚ñã        | 3/18 [00:01<00:07,  2.04it/s, Loss=0.0383]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:01<00:05,  2.57it/s, Loss=0.0383]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:02<00:05,  2.57it/s, Loss=0.0334]Training Epoch 1:  28%|‚ñà‚ñà‚ñä       | 5/18 [00:02<00:04,  3.00it/s, Loss=0.0334]Training Epoch 1:  28%|‚ñà‚ñà‚ñä       | 5/18 [00:02<00:04,  3.00it/s, Loss=0.0506]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 6/18 [00:02<00:03,  3.32it/s, Loss=0.0506]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 6/18 [00:02<00:03,  3.32it/s, Loss=0.0286]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:02<00:03,  3.58it/s, Loss=0.0286]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:02<00:03,  3.58it/s, Loss=0.0306]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 8/18 [00:02<00:02,  3.77it/s, Loss=0.0306]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 8/18 [00:03<00:02,  3.77it/s, Loss=0.0343]Training Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 9/18 [00:03<00:02,  3.91it/s, Loss=0.0343]Training Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 9/18 [00:03<00:02,  3.91it/s, Loss=0.0318]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:03<00:01,  4.01it/s, Loss=0.0318]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:03<00:01,  4.01it/s, Loss=0.0407]Training Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 11/18 [00:03<00:01,  4.07it/s, Loss=0.0407]Training Epoch 1:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 11/18 [00:03<00:01,  4.07it/s, Loss=0.0309]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 12/18 [00:03<00:01,  4.13it/s, Loss=0.0309]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 12/18 [00:04<00:01,  4.13it/s, Loss=0.0342]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:04<00:01,  4.17it/s, Loss=0.0342]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:04<00:01,  4.17it/s, Loss=0.033] Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 14/18 [00:04<00:00,  4.20it/s, Loss=0.033]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 14/18 [00:04<00:00,  4.20it/s, Loss=0.0393]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:04<00:00,  4.22it/s, Loss=0.0393]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:04<00:00,  4.22it/s, Loss=0.0299]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:04<00:00,  4.23it/s, Loss=0.0299]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:05<00:00,  4.23it/s, Loss=0.036] Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 17/18 [00:05<00:00,  4.24it/s, Loss=0.036]Training Epoch 1:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 17/18 [00:05<00:00,  4.24it/s, Loss=0.0335]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:05<00:00,  4.76it/s, Loss=0.0335]                                                                              Validation:   0%|          | 0/17 [00:00<?, ?it/s]Validation:   6%|‚ñå         | 1/17 [00:00<00:09,  1.65it/s]Validation:  12%|‚ñà‚ñè        | 2/17 [00:00<00:06,  2.47it/s]Validation:  24%|‚ñà‚ñà‚ñé       | 4/17 [00:00<00:02,  5.25it/s]Validation:  35%|‚ñà‚ñà‚ñà‚ñå      | 6/17 [00:01<00:01,  7.67it/s]Validation:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 8/17 [00:01<00:00,  9.69it/s]Validation:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 10/17 [00:01<00:00, 11.33it/s]Validation:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 12/17 [00:01<00:00, 12.59it/s]Validation:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 14/17 [00:01<00:00, 13.52it/s]Validation:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 16/17 [00:01<00:00, 14.19it/s]                                                           2024-10-01 12:19:06,904 INFO Trial 27 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_27 at: https://wandb.ai/teamdp/Cell_Classification/runs/8i2ad9at
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:19:08,940] Trial 27 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121908-syha4fs8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_28
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/syha4fs8
2024-10-01 12:19:09,624 INFO ###############################################
2024-10-01 12:19:09,625 INFO Running model: ViT32 with Image Size: 224, Batch Size: 4, LR: 0.009017328074863155, Weight Decay: 6.439659232351131e-05, Gamma: 1.0036344069213927, Alpha: 0.7189202533434338
2024-10-01 12:19:09,626 INFO ###############################################
2024-10-01 12:19:13,756 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:19:13,877 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.308]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.29it/s, Loss=0.308]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.29it/s, Loss=1.09] Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.29it/s, Loss=1.61]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:14,  2.29it/s, Loss=0.000222]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.39it/s, Loss=0.000222]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.39it/s, Loss=0.907]   Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.39it/s, Loss=0.471]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.39it/s, Loss=1.73] Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.43it/s, Loss=1.73]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.43it/s, Loss=1.83]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.43it/s, Loss=0.197]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.43it/s, Loss=1.8]  Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 17.01it/s, Loss=1.8]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 17.01it/s, Loss=1.1]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 17.01it/s, Loss=0.329]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 17.01it/s, Loss=0.121]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 19.45it/s, Loss=0.121]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 19.45it/s, Loss=0.227]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 19.45it/s, Loss=0.376]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 19.45it/s, Loss=0.609]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 21.10it/s, Loss=0.609]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 21.10it/s, Loss=0.207]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 21.10it/s, Loss=0.228]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 21.10it/s, Loss=0.491]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 21.99it/s, Loss=0.491]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 21.99it/s, Loss=0.207]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 21.99it/s, Loss=0.406]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 21.99it/s, Loss=0.249]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 23.28it/s, Loss=0.249]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 23.28it/s, Loss=0.0993]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 23.28it/s, Loss=0.508] Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 23.28it/s, Loss=0.563]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 24.37it/s, Loss=0.563]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 24.37it/s, Loss=0.241]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 24.37it/s, Loss=0.205]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 24.37it/s, Loss=0.254]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 25.16it/s, Loss=0.254]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 25.16it/s, Loss=0.265]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 25.16it/s, Loss=0.312]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 25.16it/s, Loss=0.204]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 25.74it/s, Loss=0.204]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 25.74it/s, Loss=0.204]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 25.74it/s, Loss=0.504]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 25.74it/s, Loss=0.227]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:01<00:00, 26.15it/s, Loss=0.227]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:01<00:00, 26.15it/s, Loss=0.727]                                                                             Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:12,  2.52it/s]Validation:  24%|‚ñà‚ñà‚ñç       | 8/33 [00:00<00:01, 19.78it/s]Validation:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 14/33 [00:00<00:00, 30.47it/s]Validation:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 21/33 [00:00<00:00, 39.96it/s]Validation:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 29/33 [00:00<00:00, 49.96it/s]                                                           2024-10-01 12:19:16,684 INFO Trial 28 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_28 at: https://wandb.ai/teamdp/Cell_Classification/runs/syha4fs8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:19:30,807] Trial 28 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121930-y6hvrfwx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/y6hvrfwx
2024-10-01 12:19:32,042 INFO ###############################################
2024-10-01 12:19:32,043 INFO Running model: ResNet101 with Image Size: 800, Batch Size: 16, LR: 0.00014939878639091516, Weight Decay: 2.4503878553261854e-05, Gamma: 2.741713549686001, Alpha: 0.43113568915366723
2024-10-01 12:19:32,045 INFO ###############################################
2024-10-01 12:19:36,409 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:19:36,497 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/9 [00:01<?, ?it/s, Loss=0.0466]Training Epoch 1:  11%|‚ñà         | 1/9 [00:01<00:11,  1.39s/it, Loss=0.0466]Training Epoch 1:  11%|‚ñà         | 1/9 [00:01<00:11,  1.39s/it, Loss=0.0406]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 2/9 [00:01<00:04,  1.41it/s, Loss=0.0406]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 2/9 [00:01<00:04,  1.41it/s, Loss=0.0343]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:02,  2.03it/s, Loss=0.0343]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:02<00:02,  2.03it/s, Loss=0.0331]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:02<00:01,  2.57it/s, Loss=0.0331]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 4/9 [00:02<00:01,  2.57it/s, Loss=0.028] Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:02<00:01,  3.01it/s, Loss=0.028]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:02<00:01,  3.01it/s, Loss=0.025]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:02<00:00,  3.35it/s, Loss=0.025]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 6/9 [00:02<00:00,  3.35it/s, Loss=0.0315]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:02<00:00,  3.60it/s, Loss=0.0315]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:03<00:00,  3.60it/s, Loss=0.0116]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:03<00:00,  3.80it/s, Loss=0.0116]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 8/9 [00:03<00:00,  3.80it/s, Loss=0.0271]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:03<00:00,  4.30it/s, Loss=0.0271]                                                                            Validation:   0%|          | 0/9 [00:00<?, ?it/s]Validation:  11%|‚ñà         | 1/9 [00:01<00:09,  1.16s/it]Validation:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:02,  2.78it/s]Validation:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  4.68it/s]Validation:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:01<00:00,  6.43it/s]Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:01<00:00,  8.45it/s]                                                         2024-10-01 12:19:41,617 INFO Trial 29 pruned at epoch 1
wandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.003 MB of 0.003 MB uploadedwandb: | 0.003 MB of 0.003 MB uploadedwandb: / 0.003 MB of 0.003 MB uploadedwandb: - 0.003 MB of 0.003 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_29 at: https://wandb.ai/teamdp/Cell_Classification/runs/y6hvrfwx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:19:52,125] Trial 29 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_121952-r9htl3l1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/r9htl3l1
2024-10-01 12:19:52,912 INFO ###############################################
2024-10-01 12:19:52,914 INFO Running model: EfficientNetB0 with Image Size: 500, Batch Size: 16, LR: 6.194794367116848e-05, Weight Decay: 1.33734165318818e-05, Gamma: 2.9792135569724705, Alpha: 0.5147937165921512
2024-10-01 12:19:52,915 INFO ###############################################
2024-10-01 12:19:56,893 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:19:56,919 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/9 [00:00<?, ?it/s, Loss=0.0372]Training Epoch 1:  11%|‚ñà         | 1/9 [00:00<00:07,  1.07it/s, Loss=0.0372]Training Epoch 1:  11%|‚ñà         | 1/9 [00:01<00:07,  1.07it/s, Loss=0.04]  Training Epoch 1:  11%|‚ñà         | 1/9 [00:01<00:07,  1.07it/s, Loss=0.0358]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:01,  3.35it/s, Loss=0.0358]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:01,  3.35it/s, Loss=0.0452]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 3/9 [00:01<00:01,  3.35it/s, Loss=0.0316]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  5.56it/s, Loss=0.0316]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  5.56it/s, Loss=0.0381]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:01<00:00,  5.56it/s, Loss=0.0426]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:01<00:00,  7.70it/s, Loss=0.0426]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:01<00:00,  7.70it/s, Loss=0.0332]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 7/9 [00:01<00:00,  7.70it/s, Loss=0.0267]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:01<00:00,  9.24it/s, Loss=0.0267]                                                                            Validation:   0%|          | 0/9 [00:00<?, ?it/s]Validation:  11%|‚ñà         | 1/9 [00:00<00:05,  1.44it/s]Validation:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 5/9 [00:00<00:00,  7.88it/s]                                                         2024-10-01 12:19:59,482 INFO Trial 30 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_30 at: https://wandb.ai/teamdp/Cell_Classification/runs/r9htl3l1
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:20:02,672] Trial 30 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_122002-tobpml5b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/tobpml5b
2024-10-01 12:20:03,622 INFO ###############################################
2024-10-01 12:20:03,623 INFO Running model: ViT16 with Image Size: 224, Batch Size: 8, LR: 0.00391077056366512, Weight Decay: 0.00501545297247983, Gamma: 2.313125744284054, Alpha: 0.2475547845679977
2024-10-01 12:20:03,624 INFO ###############################################
2024-10-01 12:20:07,538 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:20:07,647 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s, Loss=0.0325]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  1.98it/s, Loss=0.0325]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  1.98it/s, Loss=0.403] Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  1.98it/s, Loss=1.21] Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  1.98it/s, Loss=0.1] Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  7.68it/s, Loss=0.1]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  7.68it/s, Loss=0.466]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  7.68it/s, Loss=0.391]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  7.68it/s, Loss=0.0578]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 12.42it/s, Loss=0.0578]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 12.42it/s, Loss=0.0744]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 12.42it/s, Loss=0.029] Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 12.42it/s, Loss=0.125]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:00<00:00, 16.20it/s, Loss=0.125]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:00<00:00, 16.20it/s, Loss=0.0689]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:00<00:00, 16.20it/s, Loss=0.0523]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:00<00:00, 16.20it/s, Loss=0.0353]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:00<00:00, 19.03it/s, Loss=0.0353]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:01<00:00, 19.03it/s, Loss=0.0403]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:01<00:00, 19.03it/s, Loss=0.0422]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:01<00:00, 19.03it/s, Loss=0.106] Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:01<00:00, 21.24it/s, Loss=0.106]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:01<00:00, 21.24it/s, Loss=0.0768]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:01<00:00, 21.24it/s, Loss=0.158]                                                                              Validation:   0%|          | 0/17 [00:00<?, ?it/s]Validation:   6%|‚ñå         | 1/17 [00:00<00:07,  2.15it/s]Validation:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 9/17 [00:00<00:00, 20.39it/s]Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:00<00:00, 34.39it/s]                                                           2024-10-01 12:20:09,664 INFO Trial 31 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_31 at: https://wandb.ai/teamdp/Cell_Classification/runs/tobpml5b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:20:12,152] Trial 31 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_122012-i0rqtiom
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_32
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/i0rqtiom
2024-10-01 12:20:12,865 INFO ###############################################
2024-10-01 12:20:12,867 INFO Running model: ViT16 with Image Size: 224, Batch Size: 8, LR: 0.005787836815596046, Weight Decay: 0.0006552065513615994, Gamma: 2.1990502081758665, Alpha: 0.33653451573476867
2024-10-01 12:20:12,868 INFO ###############################################
2024-10-01 12:20:17,071 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:20:17,195 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s, Loss=0.0434]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  1.98it/s, Loss=0.0434]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  1.98it/s, Loss=0.486] Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  1.98it/s, Loss=1.58] Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  1.98it/s, Loss=0.812]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  7.80it/s, Loss=0.812]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  7.80it/s, Loss=0.626]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  7.80it/s, Loss=0.0932]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  7.80it/s, Loss=0.0739]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 12.91it/s, Loss=0.0739]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 12.91it/s, Loss=0.0421]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 12.91it/s, Loss=0.137] Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 12.91it/s, Loss=0.081]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:00<00:00, 17.00it/s, Loss=0.081]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:00<00:00, 17.00it/s, Loss=0.0482]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:00<00:00, 17.00it/s, Loss=0.0809]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:00<00:00, 17.00it/s, Loss=0.0541]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:00<00:00, 20.23it/s, Loss=0.0541]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:00<00:00, 20.23it/s, Loss=0.0498]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:00<00:00, 20.23it/s, Loss=0.0446]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:01<00:00, 20.23it/s, Loss=0.0629]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:01<00:00, 22.72it/s, Loss=0.0629]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:01<00:00, 22.72it/s, Loss=0.0437]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:01<00:00, 22.72it/s, Loss=0.0965]                                                                              Validation:   0%|          | 0/17 [00:00<?, ?it/s]Validation:   6%|‚ñå         | 1/17 [00:00<00:07,  2.19it/s]Validation:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 9/17 [00:00<00:00, 20.18it/s]                                                          2024-10-01 12:20:19,142 INFO Trial 32 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_32 at: https://wandb.ai/teamdp/Cell_Classification/runs/i0rqtiom
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:20:21,184] Trial 32 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_122021-srrh52as
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_33
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/srrh52as
2024-10-01 12:20:21,898 INFO ###############################################
2024-10-01 12:20:21,899 INFO Running model: ViT16 with Image Size: 224, Batch Size: 8, LR: 0.0012836415111054753, Weight Decay: 0.0014898332905007138, Gamma: 2.0793948771565405, Alpha: 0.1562980659102705
2024-10-01 12:20:21,899 INFO ###############################################
2024-10-01 12:20:25,858 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:20:25,983 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s, Loss=0.0226]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  1.96it/s, Loss=0.0226]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  1.96it/s, Loss=0.0329]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  1.96it/s, Loss=0.638] Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:08,  1.96it/s, Loss=0.0847]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  7.74it/s, Loss=0.0847]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  7.74it/s, Loss=0.0424]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  7.74it/s, Loss=0.213] Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:00<00:01,  7.74it/s, Loss=0.0322]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 12.75it/s, Loss=0.0322]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 12.75it/s, Loss=0.191] Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 12.75it/s, Loss=0.0471]Training Epoch 1:  39%|‚ñà‚ñà‚ñà‚ñâ      | 7/18 [00:00<00:00, 12.75it/s, Loss=0.0251]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:00<00:00, 16.95it/s, Loss=0.0251]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:00<00:00, 16.95it/s, Loss=0.0428]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:00<00:00, 16.95it/s, Loss=0.0826]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:00<00:00, 16.95it/s, Loss=0.0738]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:00<00:00, 20.26it/s, Loss=0.0738]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:00<00:00, 20.26it/s, Loss=0.0256]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:01<00:00, 20.26it/s, Loss=0.0312]Training Epoch 1:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 13/18 [00:01<00:00, 20.26it/s, Loss=0.0459]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:01<00:00, 22.88it/s, Loss=0.0459]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:01<00:00, 22.88it/s, Loss=0.0358]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:01<00:00, 22.88it/s, Loss=0.092]                                                                              Validation:   0%|          | 0/17 [00:00<?, ?it/s]Validation:   6%|‚ñå         | 1/17 [00:00<00:07,  2.11it/s]Validation:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 8/17 [00:00<00:00, 17.59it/s]                                                          2024-10-01 12:20:27,954 INFO Trial 33 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb: \ 0.005 MB of 0.005 MB uploadedwandb: | 0.005 MB of 0.005 MB uploadedwandb: / 0.005 MB of 0.005 MB uploadedwandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_33 at: https://wandb.ai/teamdp/Cell_Classification/runs/srrh52as
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:20:45,904] Trial 33 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_122045-396ef9r0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_34
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/396ef9r0
2024-10-01 12:20:46,603 INFO ###############################################
2024-10-01 12:20:46,604 INFO Running model: MobileNetV3 with Image Size: 600, Batch Size: 8, LR: 0.002590495538831831, Weight Decay: 0.0022752883028763827, Gamma: 2.5294128583522193, Alpha: 0.2464601147017082
2024-10-01 12:20:46,605 INFO ###############################################
2024-10-01 12:20:50,637 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:20:50,662 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s, Loss=0.0287]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:14,  1.19it/s, Loss=0.0287]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:14,  1.19it/s, Loss=0.0888]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:14,  1.19it/s, Loss=0.515] Training Epoch 1:  17%|‚ñà‚ñã        | 3/18 [00:00<00:03,  3.87it/s, Loss=0.515]Training Epoch 1:  17%|‚ñà‚ñã        | 3/18 [00:00<00:03,  3.87it/s, Loss=0.0233]Training Epoch 1:  17%|‚ñà‚ñã        | 3/18 [00:01<00:03,  3.87it/s, Loss=0.0371]Training Epoch 1:  17%|‚ñà‚ñã        | 3/18 [00:01<00:03,  3.87it/s, Loss=0.0114]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 6/18 [00:01<00:01,  8.11it/s, Loss=0.0114]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 6/18 [00:01<00:01,  8.11it/s, Loss=0.0366]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 6/18 [00:01<00:01,  8.11it/s, Loss=0.0196]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 6/18 [00:01<00:01,  8.11it/s, Loss=0.101] Training Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 9/18 [00:01<00:00, 12.07it/s, Loss=0.101]Training Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 9/18 [00:01<00:00, 12.07it/s, Loss=0.0107]Training Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 9/18 [00:01<00:00, 12.07it/s, Loss=0.0244]Training Epoch 1:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 9/18 [00:01<00:00, 12.07it/s, Loss=0.0212]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 12/18 [00:01<00:00, 15.54it/s, Loss=0.0212]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 12/18 [00:01<00:00, 15.54it/s, Loss=0.0204]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 12/18 [00:01<00:00, 15.54it/s, Loss=0.016] Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 12/18 [00:01<00:00, 15.54it/s, Loss=0.0244]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:01<00:00, 18.43it/s, Loss=0.0244]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:01<00:00, 18.43it/s, Loss=0.0266]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:01<00:00, 18.43it/s, Loss=0.0225]Training Epoch 1:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 15/18 [00:01<00:00, 18.43it/s, Loss=0.0249]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:01<00:00, 19.20it/s, Loss=0.0249]                                                                              Validation:   0%|          | 0/17 [00:00<?, ?it/s]Validation:   6%|‚ñå         | 1/17 [00:00<00:09,  1.63it/s]Validation:  41%|‚ñà‚ñà‚ñà‚ñà      | 7/17 [00:00<00:00, 12.50it/s]Validation:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 12/17 [00:00<00:00, 20.37it/s]                                                           2024-10-01 12:20:53,238 INFO Trial 34 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_34 at: https://wandb.ai/teamdp/Cell_Classification/runs/396ef9r0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:20:55,330] Trial 34 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_122055-8mupga3l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_35
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/8mupga3l
2024-10-01 12:20:56,256 INFO ###############################################
2024-10-01 12:20:56,256 INFO Running model: ViT16 with Image Size: 224, Batch Size: 4, LR: 0.0035852361336272376, Weight Decay: 0.00023943847098445437, Gamma: 1.168256788156915, Alpha: 0.3321423099721485
2024-10-01 12:20:56,257 INFO ###############################################
2024-10-01 12:21:00,243 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:21:00,362 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/35 [00:00<?, ?it/s, Loss=0.0947]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:15,  2.15it/s, Loss=0.0947]Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:15,  2.15it/s, Loss=0.546] Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:15,  2.15it/s, Loss=1.3]  Training Epoch 1:   3%|‚ñé         | 1/35 [00:00<00:15,  2.15it/s, Loss=0.355]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.45it/s, Loss=0.355]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.45it/s, Loss=0.376]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.45it/s, Loss=0.429]Training Epoch 1:  11%|‚ñà‚ñè        | 4/35 [00:00<00:03,  8.45it/s, Loss=0.104]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.21it/s, Loss=0.104]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.21it/s, Loss=0.122]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.21it/s, Loss=0.0804]Training Epoch 1:  20%|‚ñà‚ñà        | 7/35 [00:00<00:02, 13.21it/s, Loss=0.208] Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 16.97it/s, Loss=0.208]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 16.97it/s, Loss=0.107]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 16.97it/s, Loss=0.179]Training Epoch 1:  29%|‚ñà‚ñà‚ñä       | 10/35 [00:00<00:01, 16.97it/s, Loss=0.141]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 18.79it/s, Loss=0.141]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:00<00:01, 18.79it/s, Loss=0.114]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 18.79it/s, Loss=0.145]Training Epoch 1:  37%|‚ñà‚ñà‚ñà‚ñã      | 13/35 [00:01<00:01, 18.79it/s, Loss=0.034]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 20.23it/s, Loss=0.034]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 20.23it/s, Loss=0.145]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 20.23it/s, Loss=0.0824]Training Epoch 1:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 16/35 [00:01<00:00, 20.23it/s, Loss=0.108] Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 21.22it/s, Loss=0.108]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 21.22it/s, Loss=0.0995]Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 21.22it/s, Loss=0.151] Training Epoch 1:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 19/35 [00:01<00:00, 21.22it/s, Loss=0.084]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 22.79it/s, Loss=0.084]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 22.79it/s, Loss=0.0835]Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 22.79it/s, Loss=0.125] Training Epoch 1:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 22/35 [00:01<00:00, 22.79it/s, Loss=0.0851]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 24.05it/s, Loss=0.0851]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 24.05it/s, Loss=0.0871]Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 24.05it/s, Loss=0.124] Training Epoch 1:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 25/35 [00:01<00:00, 24.05it/s, Loss=0.103]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 25.06it/s, Loss=0.103]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 25.06it/s, Loss=0.0948]Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 25.06it/s, Loss=0.153] Training Epoch 1:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 28/35 [00:01<00:00, 25.06it/s, Loss=0.102]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 25.80it/s, Loss=0.102]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 25.80it/s, Loss=0.093]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 25.80it/s, Loss=0.117]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 31/35 [00:01<00:00, 25.80it/s, Loss=0.0837]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:01<00:00, 26.35it/s, Loss=0.0837]Training Epoch 1:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 34/35 [00:01<00:00, 26.35it/s, Loss=0.0323]                                                                              Validation:   0%|          | 0/33 [00:00<?, ?it/s]Validation:   3%|‚ñé         | 1/33 [00:00<00:13,  2.44it/s]Validation:  27%|‚ñà‚ñà‚ñã       | 9/33 [00:00<00:01, 21.93it/s]Validation:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 17/33 [00:00<00:00, 36.93it/s]Validation:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 27/33 [00:00<00:00, 52.63it/s]                                                           2024-10-01 12:21:03,128 INFO Trial 35 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_35 at: https://wandb.ai/teamdp/Cell_Classification/runs/8mupga3l
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:21:05,491] Trial 35 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_122105-em3602am
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_36
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/em3602am
2024-10-01 12:21:06,212 INFO ###############################################
2024-10-01 12:21:06,214 INFO Running model: ResNet18 with Image Size: 500, Batch Size: 32, LR: 0.00040240343961046735, Weight Decay: 0.00010648467864326033, Gamma: 1.8077274118375144, Alpha: 0.17221451114684327
2024-10-01 12:21:06,215 INFO ###############################################
2024-10-01 12:21:10,272 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:21:10,302 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/5 [00:00<?, ?it/s, Loss=0.0356]Training Epoch 1:  20%|‚ñà‚ñà        | 1/5 [00:00<00:03,  1.00it/s, Loss=0.0356]Training Epoch 1:  20%|‚ñà‚ñà        | 1/5 [00:01<00:03,  1.00it/s, Loss=0.0221]Training Epoch 1:  20%|‚ñà‚ñà        | 1/5 [00:01<00:03,  1.00it/s, Loss=0.00569]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:01<00:00,  3.29it/s, Loss=0.00569]Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:01<00:00,  3.29it/s, Loss=0.0146] Training Epoch 1:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 3/5 [00:01<00:00,  3.29it/s, Loss=0.0134]                                                                            Validation:   0%|          | 0/5 [00:00<?, ?it/s]Validation:  20%|‚ñà‚ñà        | 1/5 [00:00<00:03,  1.15it/s]Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00,  6.44it/s]                                                         2024-10-01 12:21:12,726 INFO Trial 36 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_36 at: https://wandb.ai/teamdp/Cell_Classification/runs/em3602am
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:21:14,834] Trial 36 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_122114-5pupsli4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_37
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/5pupsli4
2024-10-01 12:21:15,949 INFO ###############################################
2024-10-01 12:21:15,951 INFO Running model: DenseNet121 with Image Size: 600, Batch Size: 8, LR: 0.0013762158695967838, Weight Decay: 1.996820425582886e-06, Gamma: 2.3826734920831365, Alpha: 0.47897424477391826
2024-10-01 12:21:15,951 INFO ###############################################
2024-10-01 12:21:20,153 INFO Using a single GPU.
/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/pydantic/main.py:212: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.
  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)
2024-10-01 12:21:20,196 INFO Epoch 1/1
Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s]Training Epoch 1:   0%|          | 0/18 [00:00<?, ?it/s, Loss=0.115]Training Epoch 1:   6%|‚ñå         | 1/18 [00:00<00:15,  1.09it/s, Loss=0.115]Training Epoch 1:   6%|‚ñå         | 1/18 [00:01<00:15,  1.09it/s, Loss=0.118]Training Epoch 1:  11%|‚ñà         | 2/18 [00:01<00:07,  2.16it/s, Loss=0.118]Training Epoch 1:  11%|‚ñà         | 2/18 [00:01<00:07,  2.16it/s, Loss=0.0507]Training Epoch 1:  11%|‚ñà         | 2/18 [00:01<00:07,  2.16it/s, Loss=0.113] Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:01<00:03,  4.32it/s, Loss=0.113]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:01<00:03,  4.32it/s, Loss=0.0973]Training Epoch 1:  22%|‚ñà‚ñà‚ñè       | 4/18 [00:01<00:03,  4.32it/s, Loss=0.00831]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 6/18 [00:01<00:01,  6.06it/s, Loss=0.00831]Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 6/18 [00:01<00:01,  6.06it/s, Loss=0.0173] Training Epoch 1:  33%|‚ñà‚ñà‚ñà‚ñé      | 6/18 [00:01<00:01,  6.06it/s, Loss=0.406] Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 8/18 [00:01<00:01,  7.40it/s, Loss=0.406]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 8/18 [00:01<00:01,  7.40it/s, Loss=0.0363]Training Epoch 1:  44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 8/18 [00:01<00:01,  7.40it/s, Loss=0.0382]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:01<00:00,  8.41it/s, Loss=0.0382]Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:01<00:00,  8.41it/s, Loss=0.118] Training Epoch 1:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 10/18 [00:01<00:00,  8.41it/s, Loss=0.0894]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 12/18 [00:01<00:00,  9.16it/s, Loss=0.0894]Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 12/18 [00:02<00:00,  9.16it/s, Loss=0.161] Training Epoch 1:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 12/18 [00:02<00:00,  9.16it/s, Loss=0.0536]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 14/18 [00:02<00:00,  9.70it/s, Loss=0.0536]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 14/18 [00:02<00:00,  9.70it/s, Loss=0.0549]Training Epoch 1:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 14/18 [00:02<00:00,  9.70it/s, Loss=0.0654]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:02<00:00, 10.09it/s, Loss=0.0654]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:02<00:00, 10.09it/s, Loss=0.0591]Training Epoch 1:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 16/18 [00:02<00:00, 10.09it/s, Loss=0.0736]Training Epoch 1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 18/18 [00:02<00:00,  8.42it/s, Loss=0.0736]                                                                              Validation:   0%|          | 0/17 [00:00<?, ?it/s]Validation:   6%|‚ñå         | 1/17 [00:00<00:11,  1.44it/s]Validation:  29%|‚ñà‚ñà‚ñâ       | 5/17 [00:00<00:01,  7.79it/s]Validation:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 9/17 [00:00<00:00, 13.60it/s]Validation:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 13/17 [00:01<00:00, 18.62it/s]Validation: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17/17 [00:01<00:00, 23.16it/s]                                                           2024-10-01 12:21:24,181 INFO Trial 37 pruned at epoch 1
wandb: - 0.005 MB of 0.005 MB uploadedwandb:                                                                                
wandb: üöÄ View run trial_37 at: https://wandb.ai/teamdp/Cell_Classification/runs/5pupsli4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/teamdp/Cell_Classification
wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
[I 2024-10-01 12:21:26,846] Trial 37 pruned. 
wandb: Tracking run with wandb version 0.18.2
wandb: Run data is saved locally in /work3/s204148/DM-i-AI-2024/Cell_Classification/wandb/run-20241001_122126-sdf3jvru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trial_38
wandb: ‚≠êÔ∏è View project at https://wandb.ai/teamdp/Cell_Classification
wandb: üöÄ View run at https://wandb.ai/teamdp/Cell_Classification/runs/sdf3jvru
2024-10-01 12:21:27,550 INFO ###############################################
2024-10-01 12:21:27,551 INFO Running model: ViT16 with Image Size: 224, Batch Size: 4, LR: 1.0631189192029166e-06, Weight Decay: 5.262879031572436e-06, Gamma: 1.9581037322175094, Alpha: 0.3655016680406189
2024-10-01 12:21:27,552 INFO ###############################################
[W 2024-10-01 12:21:28,028] Trial 38 failed with parameters: {'model_name': 'ViT16', 'batch_size': 4, 'lr': 1.0631189192029166e-06, 'weight_decay': 5.262879031572436e-06, 'gamma': 1.9581037322175094, 'alpha': 0.3655016680406189} because of the following error: KeyboardInterrupt().
Traceback (most recent call last):
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/src/train_model.py", line 460, in objective
    models_dict = get_models()
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/src/train_model.py", line 212, in get_models
    vit_model = models.vit_b_16(weights=vit_weights)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/_utils.py", line 142, in wrapper
    return fn(*args, **kwargs)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/_utils.py", line 228, in inner_wrapper
    return builder(*args, **kwargs)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py", line 641, in vit_b_16
    return _vision_transformer(
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py", line 324, in _vision_transformer
    model = VisionTransformer(
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py", line 223, in __init__
    self.encoder = Encoder(
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py", line 143, in __init__
    layers[f"encoder_layer_{i}"] = EncoderBlock(
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py", line 108, in __init__
    self.mlp = MLPBlock(hidden_dim, mlp_dim, dropout)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py", line 50, in __init__
    nn.init.xavier_uniform_(m.weight)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torch/nn/init.py", line 363, in xavier_uniform_
    return _no_grad_uniform_(tensor, -a, a, generator)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torch/nn/init.py", line 16, in _no_grad_uniform_
    return tensor.uniform_(a, b, generator=generator)
KeyboardInterrupt
[W 2024-10-01 12:21:28,038] Trial 38 failed with value None.
Traceback (most recent call last):
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/src/train_model.py", line 628, in <module>
    study.optimize(objective, n_trials=200, timeout=None)  # Increased n_trials for better hyperparameter exploration
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/optuna/study/study.py", line 475, in optimize
    _optimize(
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/optuna/study/_optimize.py", line 63, in _optimize
    _optimize_sequential(
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/optuna/study/_optimize.py", line 160, in _optimize_sequential
    frozen_trial = _run_trial(study, func, catch)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/optuna/study/_optimize.py", line 248, in _run_trial
    raise func_err
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/optuna/study/_optimize.py", line 197, in _run_trial
    value_or_values = func(trial)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/src/train_model.py", line 460, in objective
    models_dict = get_models()
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/src/train_model.py", line 212, in get_models
    vit_model = models.vit_b_16(weights=vit_weights)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/_utils.py", line 142, in wrapper
    return fn(*args, **kwargs)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/_utils.py", line 228, in inner_wrapper
    return builder(*args, **kwargs)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py", line 641, in vit_b_16
    return _vision_transformer(
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py", line 324, in _vision_transformer
    model = VisionTransformer(
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py", line 223, in __init__
    self.encoder = Encoder(
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py", line 143, in __init__
    layers[f"encoder_layer_{i}"] = EncoderBlock(
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py", line 108, in __init__
    self.mlp = MLPBlock(hidden_dim, mlp_dim, dropout)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torchvision/models/vision_transformer.py", line 50, in __init__
    nn.init.xavier_uniform_(m.weight)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torch/nn/init.py", line 363, in xavier_uniform_
    return _no_grad_uniform_(tensor, -a, a, generator)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/torch/nn/init.py", line 16, in _no_grad_uniform_
    return tensor.uniform_(a, b, generator=generator)
KeyboardInterrupt
Exception ignored in atexit callback: <function _start_and_connect_service.<locals>.teardown_atexit at 0x7f353c9b3370>
Traceback (most recent call last):
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py", line 93, in teardown_atexit
    conn.teardown(hooks.exit_code)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/wandb/sdk/lib/service_connection.py", line 210, in teardown
    self._client.send(
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 215, in send
    self.send_server_request(server_req)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 157, in send_server_request
    self._send_message(msg)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 154, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/work3/s204148/DM-i-AI-2024/Cell_Classification/cell_venv/lib/python3.10/site-packages/wandb/sdk/lib/sock_client.py", line 132, in _sendall_with_error_handle
    sent = self._sock.send(data)
BrokenPipeError: [Errno 32] Broken pipe
